liurui@ubuntu:~/DeepRec$ KERAS_BACKEND=theano python v3_random_train/MLP.py --learner adam --batch_size_random 1280000 --reg_layers [0,0,0,0] --lr 0.00001
Using Theano backend.
MLP arguments: Namespace(batch_size=256, batch_size_random=1280000, epochs=100, layers='[64,32,16,8]', learner='adam', lr=1e-05, path='Data/yelp/', reg_layers='[0,0,0,0]', verbose=1) 
Load data done [154.3 s]. #user=13679, #item=12922, #train=15651858, #test=316795
Time: [70.3], Init: NDCG = 
[ 0.55974248  0.56535734  0.57354256  0.58316207  0.59577706  0.61005896
  0.6271598   0.64528411  0.66534612  0.68758048]
Iteration 0 [105.1 s]: loss = 0.692543 [68.83 s], NDCG = 
[ 0.68937274  0.68202626  0.68049818  0.68585014  0.69328564  0.70346278
  0.71564285  0.72978902  0.74585677  0.76294333]
Iteration 1 [106.8 s]: loss = 0.683351 [68.49 s], NDCG = 
[ 0.72770447  0.71865899  0.71771037  0.7202089   0.72661609  0.7356087
  0.74642668  0.75918341  0.77315387  0.78852272]
Iteration 2 [105.3 s]: loss = 0.654501 [71.71 s], NDCG = 
[ 0.74127774  0.73001459  0.72822635  0.7302663   0.73640692  0.74450126
  0.75467061  0.76703552  0.78053546  0.79551637]
Iteration 3 [107.8 s]: loss = 0.628589 [72.46 s], NDCG = 
[ 0.74836938  0.73661459  0.7346214   0.73565845  0.74144812  0.74961242
  0.75954979  0.77138674  0.78464534  0.7991066 ]
Iteration 4 [106.9 s]: loss = 0.619309 [71.62 s], NDCG = 
[ 0.75353387  0.74153016  0.73804992  0.73932231  0.7442557   0.75235031
  0.76225437  0.77378829  0.78712574  0.80124886]
Iteration 5 [106.6 s]: loss = 0.615308 [71.38 s], NDCG = 
[ 0.7572281   0.74346515  0.73991833  0.74094022  0.74560322  0.75358453
  0.76353838  0.77532453  0.78853428  0.80253962]
Iteration 6 [106.8 s]: loss = 0.612728 [71.67 s], NDCG = 
[ 0.75728124  0.745087    0.74144029  0.74178973  0.74623451  0.75447491
  0.76439449  0.77585386  0.78915062  0.80305228]
Iteration 7 [106.3 s]: loss = 0.610689 [71.70 s], NDCG = 
[ 0.76039377  0.74515418  0.74210244  0.74194511  0.74682459  0.75480654
  0.7645575   0.77615945  0.78921668  0.80329225]
Iteration 8 [106.7 s]: loss = 0.608964 [72.63 s], NDCG = 
[ 0.76090441  0.7450093   0.74198569  0.74249096  0.74671691  0.75446839
  0.76471334  0.77651234  0.78905345  0.80316472]
Iteration 9 [106.4 s]: loss = 0.607422 [72.53 s], NDCG = 
[ 0.7610088   0.74542771  0.74197009  0.74260336  0.74710312  0.75484842
  0.76487057  0.77644701  0.78926276  0.80345625]
Iteration 10 [106.0 s]: loss = 0.605596 [71.16 s], NDCG = 
[ 0.7621986   0.7466321   0.741678    0.7423739   0.74689711  0.75458093
  0.76472918  0.77631109  0.78917366  0.80344775]
Iteration 11 [104.4 s]: loss = 0.603743 [71.40 s], NDCG = 
[ 0.76111633  0.74624071  0.74149331  0.74218846  0.74687085  0.75428438
  0.76431759  0.77578493  0.78885469  0.80321116]
Iteration 12 [105.8 s]: loss = 0.601936 [73.05 s], NDCG = 
[ 0.76223727  0.74638652  0.74101349  0.74193936  0.74630943  0.75422923
  0.76461722  0.77584321  0.78894637  0.80328171]
Iteration 13 [107.1 s]: loss = 0.600145 [72.81 s], NDCG = 
[ 0.76380722  0.7459816   0.74124974  0.74164865  0.74643875  0.7536311
  0.76406357  0.77557038  0.78861128  0.8030019 ]
Iteration 14 [106.3 s]: loss = 0.598874 [72.67 s], NDCG = 
[ 0.76351888  0.74559281  0.74142473  0.74125441  0.74590839  0.75382089
  0.76370209  0.77532696  0.78842043  0.80265678]
Iteration 15 [103.6 s]: loss = 0.596604 [70.91 s], NDCG = 
[ 0.76252151  0.74642109  0.74147408  0.74151947  0.74583755  0.75351793
  0.76377864  0.7755298   0.78839884  0.80279955]
Iteration 16 [102.9 s]: loss = 0.595501 [71.42 s], NDCG = 
[ 0.76284821  0.74624066  0.7412633   0.74141689  0.74572195  0.75347098
  0.76331478  0.77508184  0.78817591  0.80233639]
Iteration 17 [103.4 s]: loss = 0.594243 [71.10 s], NDCG = 
[ 0.76312459  0.74646844  0.7416337   0.74204728  0.74610951  0.75360186
  0.76389135  0.7754731   0.78877269  0.80292631]
Iteration 18 [103.5 s]: loss = 0.592475 [70.80 s], NDCG = 
[ 0.76360724  0.74644684  0.74231918  0.74166418  0.74558089  0.75316891
  0.76325641  0.77518828  0.78867977  0.80266822]
Iteration 19 [103.4 s]: loss = 0.590501 [70.89 s], NDCG = 
[ 0.76381759  0.74699465  0.74216002  0.7421218   0.74595404  0.75342982
  0.76293206  0.77495564  0.78851658  0.80289875]
Iteration 20 [102.8 s]: loss = 0.589620 [71.10 s], NDCG = 
[ 0.76415403  0.74719204  0.7421405   0.74196731  0.74582482  0.75345417
  0.76338431  0.77498938  0.78831557  0.80256694]
Iteration 21 [102.5 s]: loss = 0.587496 [71.59 s], NDCG = 
[ 0.76550796  0.74726748  0.74185439  0.74207048  0.74553395  0.75282012
  0.76315771  0.77486139  0.78806234  0.80231174]
Iteration 22 [103.0 s]: loss = 0.585921 [70.76 s], NDCG = 
[ 0.76472912  0.74624026  0.74103725  0.74111422  0.74537513  0.75272805
  0.76258685  0.7744518   0.78761546  0.80178972]
Iteration 23 [103.3 s]: loss = 0.584163 [71.03 s], NDCG = 
[ 0.76293692  0.74534017  0.74040849  0.74114203  0.74476926  0.75215572
  0.76186211  0.77387758  0.78703685  0.80115647]
Iteration 24 [102.6 s]: loss = 0.582410 [71.38 s], NDCG = 
[ 0.76302685  0.74525793  0.73962384  0.73987648  0.74441137  0.75185829
  0.76146896  0.77326723  0.78665776  0.80091767]
Iteration 25 [102.6 s]: loss = 0.580811 [70.93 s], NDCG = 
[ 0.76296459  0.74429714  0.73885981  0.73913343  0.74329788  0.75083825
  0.76050618  0.77249504  0.78574242  0.8003906 ]
Iteration 26 [103.5 s]: loss = 0.578960 [70.94 s], NDCG = 
[ 0.7625212   0.74362248  0.73820653  0.73840478  0.74254465  0.75012801
  0.76020915  0.77203237  0.78556605  0.79973165]
Iteration 27 [102.3 s]: loss = 0.577020 [71.37 s], NDCG = 
[ 0.76073749  0.74314993  0.73697315  0.73720498  0.74116995  0.7489685
  0.75887032  0.77074254  0.78434863  0.7986182 ]
Iteration 28 [102.5 s]: loss = 0.575134 [71.31 s], NDCG = 
[ 0.75916503  0.74102664  0.73500984  0.73586294  0.73989589  0.74783298
  0.75773068  0.76961181  0.78319804  0.79758993]
Iteration 29 [103.2 s]: loss = 0.573169 [62.60 s], NDCG = 
[ 0.76013316  0.74127405  0.73469161  0.73585804  0.73925251  0.74719135
  0.75716222  0.76943277  0.78286457  0.79731137]
Iteration 30 [99.9 s]: loss = 0.571227 [62.78 s], NDCG = 
[ 0.75834217  0.73992993  0.73345805  0.73430589  0.73811594  0.74634636
  0.75617036  0.76867115  0.78222675  0.7964738 ]
Iteration 31 [99.8 s]: loss = 0.569530 [62.64 s], NDCG = 
[ 0.75816573  0.73938805  0.73288753  0.73348029  0.73752012  0.7454795
  0.75571487  0.76774732  0.78118116  0.79581473]
Iteration 32 [99.9 s]: loss = 0.567146 [62.76 s], NDCG = 
[ 0.75725011  0.73781703  0.73151627  0.73259402  0.73657924  0.74500467
  0.75483321  0.76671864  0.78037724  0.79503174]
Iteration 33 [99.9 s]: loss = 0.564520 [62.55 s], NDCG = 
[ 0.75600277  0.7367243   0.73107081  0.73136843  0.73565296  0.74406455
  0.75398204  0.76610784  0.77971007  0.79437299]
Iteration 34 [99.5 s]: loss = 0.562047 [62.60 s], NDCG = 
[ 0.75503276  0.73545636  0.72981584  0.73037503  0.73494196  0.74283004
  0.75294005  0.76524397  0.77896357  0.79369283]
Iteration 35 [100.3 s]: loss = 0.559142 [62.90 s], NDCG = 
[ 0.75285785  0.73382522  0.72820614  0.72913878  0.73367276  0.74182327
  0.7523817   0.7648266   0.7783966   0.79308401]
Iteration 36 [99.7 s]: loss = 0.557200 [62.62 s], NDCG = 
[ 0.75199411  0.73234743  0.7271897   0.72798052  0.73268294  0.74114362
  0.75128889  0.76348925  0.77729574  0.79240564]
Iteration 37 [99.7 s]: loss = 0.555277 [62.50 s], NDCG = 
[ 0.74973211  0.73075298  0.72614581  0.72697772  0.73211007  0.73995046
  0.75035462  0.76255376  0.77649854  0.79182366]
Iteration 38 [99.6 s]: loss = 0.551945 [67.01 s], NDCG = 
[ 0.74738836  0.73029901  0.72515222  0.72558277  0.73093382  0.73902041
  0.74954717  0.76205769  0.77589243  0.79081982]
Iteration 39 [106.7 s]: loss = 0.550483 [72.97 s], NDCG = 
[ 0.7459816   0.72847714  0.7237002   0.72458097  0.72962266  0.73780778
  0.74873883  0.76102723  0.77468277  0.79019044]
Iteration 40 [104.9 s]: loss = 0.547419 [72.55 s], NDCG = 
[ 0.74315457  0.72720492  0.72212622  0.72350264  0.7283976   0.73658481
  0.74729678  0.75976501  0.77398976  0.78918896]
Iteration 41 [104.8 s]: loss = 0.544910 [72.71 s], NDCG = 
[ 0.74101268  0.72631338  0.72105866  0.72267992  0.72734824  0.73594874
  0.74667476  0.7594371   0.77315287  0.78865031]
Iteration 42 [104.9 s]: loss = 0.542963 [72.69 s], NDCG = 
[ 0.74002474  0.72477434  0.71998477  0.72122523  0.72658154  0.73502158
  0.74550832  0.75811278  0.77224312  0.78764658]
Iteration 43 [104.5 s]: loss = 0.539574 [72.88 s], NDCG = 
[ 0.73825325  0.72367667  0.71850382  0.7201625   0.72526056  0.73381397
  0.7446298   0.75721831  0.77125121  0.78681743]
Iteration 44 [105.2 s]: loss = 0.537367 [72.86 s], NDCG = 
[ 0.73714237  0.7230942   0.71773674  0.71887523  0.7244072   0.73285775
  0.74382555  0.75616561  0.77052684  0.78616889]
Iteration 45 [105.0 s]: loss = 0.534562 [72.44 s], NDCG = 
[ 0.7355718   0.72178718  0.71672565  0.71834191  0.72352114  0.73239486
  0.74291837  0.75575381  0.77004701  0.78563506]
Iteration 46 [104.8 s]: loss = 0.532418 [72.30 s], NDCG = 
[ 0.73549728  0.72086506  0.71647478  0.71784713  0.72327687  0.73163094
  0.74267623  0.75518895  0.76964779  0.78516852]
Iteration 47 [104.6 s]: loss = 0.529215 [72.32 s], NDCG = 
[ 0.73286268  0.71906947  0.71479966  0.71654369  0.72204818  0.73029942
  0.74139989  0.75406163  0.7685156   0.78416714]
Iteration 48 [105.0 s]: loss = 0.526177 [72.46 s], NDCG = 
[ 0.7296489   0.71770841  0.71305677  0.7148753   0.72097034  0.72912041
  0.74020563  0.75285972  0.7674632   0.78322763]
Iteration 49 [104.4 s]: loss = 0.523303 [72.62 s], NDCG = 
[ 0.72815316  0.71598837  0.71155703  0.71381424  0.71964035  0.72824819
  0.73947433  0.75202472  0.76661386  0.78257072]
Iteration 50 [104.9 s]: loss = 0.520741 [72.68 s], NDCG = 
[ 0.7273935   0.71575526  0.71082609  0.71287112  0.71860216  0.7271772
  0.73846976  0.75123953  0.76578323  0.78207617]
Iteration 51 [104.6 s]: loss = 0.517442 [72.57 s], NDCG = 
[ 0.72517929  0.71284515  0.70899453  0.71152469  0.71682688  0.72556741
  0.7367457   0.74989951  0.76485586  0.78087674]
Iteration 52 [105.1 s]: loss = 0.514427 [72.38 s], NDCG = 
[ 0.72624332  0.71202425  0.70888152  0.71086876  0.71633668  0.72518503
  0.73653335  0.74944474  0.76445677  0.78073007]
Iteration 53 [104.1 s]: loss = 0.511803 [72.50 s], NDCG = 
[ 0.72210197  0.71002012  0.70733574  0.7092666   0.71490201  0.72374116
  0.73533016  0.74834159  0.76336764  0.77963368]
Iteration 54 [104.9 s]: loss = 0.508219 [72.68 s], NDCG = 
[ 0.72128477  0.70867671  0.70570866  0.70814634  0.71392652  0.72284902
  0.73433612  0.74768818  0.76265027  0.77881941]
Iteration 55 [104.1 s]: loss = 0.505307 [72.15 s], NDCG = 
[ 0.71741478  0.70607195  0.70338997  0.706596    0.71259148  0.72147511
  0.73314824  0.74648966  0.76173204  0.77779599]
Iteration 56 [103.6 s]: loss = 0.502735 [72.25 s], NDCG = 
[ 0.71803232  0.70560798  0.70375443  0.70640569  0.71202344  0.72098668
  0.73269189  0.7460243   0.76125712  0.77728733]
Iteration 57 [105.0 s]: loss = 0.499368 [72.75 s], NDCG = 
[ 0.71605456  0.70423972  0.70184891  0.7044582   0.71066559  0.71985363
  0.7316972   0.74494537  0.76016155  0.77627193]
Iteration 58 [104.7 s]: loss = 0.496523 [72.69 s], NDCG = 
[ 0.71438525  0.70244909  0.70075649  0.70346336  0.70993355  0.71891378
  0.73070423  0.74408916  0.75920247  0.77550277]
Iteration 59 [103.5 s]: loss = 0.493515 [72.16 s], NDCG = 
[ 0.71549456  0.70287333  0.7008427   0.70323554  0.71027614  0.71876891
  0.73075706  0.74400022  0.759302    0.77549686]
Iteration 60 [104.2 s]: loss = 0.490232 [72.32 s], NDCG = 
[ 0.71337688  0.70127624  0.69977518  0.70243116  0.70935673  0.71797019
  0.72991487  0.74335916  0.75862648  0.77485029]
Iteration 61 [104.2 s]: loss = 0.487874 [72.24 s], NDCG = 
[ 0.71130542  0.69971285  0.69811116  0.70138754  0.70761196  0.71706107
  0.72930011  0.74262837  0.75802511  0.77434759]
Iteration 62 [104.2 s]: loss = 0.484608 [72.13 s], NDCG = 
[ 0.71001878  0.6991213   0.69749838  0.70007972  0.70703157  0.71634373
  0.72830648  0.74224931  0.757501    0.77363738]
Iteration 63 [104.6 s]: loss = 0.482125 [72.75 s], NDCG = 
[ 0.7094069   0.69842375  0.69691217  0.69966513  0.70631085  0.71554366
  0.72740335  0.74146434  0.75659872  0.77304564]
Iteration 64 [103.6 s]: loss = 0.478805 [72.29 s], NDCG = 
[ 0.70719206  0.69774123  0.69581506  0.69836904  0.70511961  0.71465786
  0.72675059  0.74049221  0.75569975  0.77228468]
Iteration 65 [104.1 s]: loss = 0.475911 [72.03 s], NDCG = 
[ 0.70626575  0.69628418  0.69480878  0.69783726  0.7043953   0.71382994
  0.72603178  0.73987617  0.75511193  0.77184464]
Iteration 66 [104.5 s]: loss = 0.473645 [72.50 s], NDCG = 
[ 0.70578629  0.69593478  0.69433533  0.6968855   0.70318745  0.71320198
  0.72576955  0.73947539  0.75473507  0.77133453]
Iteration 67 [104.2 s]: loss = 0.470917 [72.68 s], NDCG = 
[ 0.70450338  0.69480491  0.69333179  0.69576075  0.70268554  0.71259179
  0.72485327  0.73869131  0.75421698  0.77079128]
Iteration 68 [104.4 s]: loss = 0.467404 [72.67 s], NDCG = 
[ 0.7030721   0.69329841  0.69203944  0.69504996  0.70189165  0.71187172
  0.72434457  0.73795359  0.75343284  0.77001082]
Iteration 69 [105.4 s]: loss = 0.465389 [72.04 s], NDCG = 
[ 0.70149775  0.69258448  0.69169336  0.6945428   0.70131879  0.71131709
  0.72364705  0.73709206  0.75273881  0.76944105]
Iteration 70 [100.1 s]: loss = 0.461986 [63.69 s], NDCG = 
[ 0.69977877  0.6921778   0.69100452  0.69431582  0.70080435  0.71102052
  0.72294106  0.73689813  0.75244369  0.76913343]
Iteration 71 [100.3 s]: loss = 0.459833 [63.49 s], NDCG = 
[ 0.69761738  0.69041114  0.68950636  0.69260335  0.69972097  0.7095174
  0.72176084  0.73557178  0.75165978  0.76819972]
Iteration 72 [99.4 s]: loss = 0.456802 [63.39 s], NDCG = 
[ 0.69703411  0.68994604  0.68912667  0.69215562  0.69945386  0.70920492
  0.72142919  0.73539949  0.75106185  0.76792221]
Iteration 73 [99.1 s]: loss = 0.454691 [63.27 s], NDCG = 
[ 0.69518684  0.68779578  0.68824392  0.69133232  0.69839855  0.70850103
  0.72088934  0.7345404   0.75040269  0.76723597]
Iteration 74 [99.4 s]: loss = 0.452446 [63.28 s], NDCG = 
[ 0.69503812  0.68834881  0.68763054  0.69113423  0.69835259  0.70802799
  0.72041873  0.73435571  0.74999138  0.76690145]
Iteration 75 [99.6 s]: loss = 0.449335 [63.33 s], NDCG = 
[ 0.69552234  0.68790634  0.68733588  0.69110709  0.69780317  0.70769479
  0.72040285  0.73418883  0.75004881  0.76676833]
Iteration 76 [99.4 s]: loss = 0.447411 [63.50 s], NDCG = 
[ 0.69132911  0.68549072  0.68549311  0.68947638  0.6960414   0.70579544
  0.71893199  0.73262518  0.74858379  0.76522604]
Iteration 77 [99.4 s]: loss = 0.444444 [63.24 s], NDCG = 
[ 0.69138948  0.68582118  0.68494061  0.68862244  0.69591391  0.70562357
  0.71867508  0.73274399  0.74870755  0.7651937 ]
Iteration 78 [99.6 s]: loss = 0.442069 [63.37 s], NDCG = 
[ 0.68996732  0.68499867  0.68465092  0.68839507  0.69559925  0.70498914
  0.71805857  0.73223226  0.74814069  0.76480676]



liurui@ubuntu:~/DeepRec$ KERAS_BACKEND=theano python v3_random_train/MLP.py --learner adam --batch_size_random 1280000 --reg_layers [0.000001,0.001,0.002,0.004] --lr 0.00001
Using Theano backend.
MLP arguments: Namespace(batch_size=256, batch_size_random=1280000, epochs=100, layers='[64,32,16,8]', learner='adam', lr=1e-05, path='Data/yelp/', reg_layers='[0.000001,0.001,0.002,0.004]', verbose=1) 
Load data done [146.9 s]. #user=13679, #item=12922, #train=15651858, #test=316795
Time: [72.8], Init: NDCG = 
[ 0.55649847  0.56202583  0.57124811  0.58194044  0.59452012  0.60931269
  0.62584665  0.64434651  0.66527733  0.68730223]
Iteration 0 [95.4 s]: loss = 0.897120 [71.60 s], NDCG = 
[ 0.69299622  0.68604002  0.68449277  0.68874038  0.69585967  0.70529442
  0.71696735  0.73054199  0.74618192  0.7630769 ]
Iteration 1 [90.1 s]: loss = 0.819316 [72.76 s], NDCG = 
[ 0.72328108  0.71503709  0.71491008  0.71849347  0.72511075  0.73437471
  0.74478614  0.75723398  0.77103475  0.78640387]
Iteration 2 [89.6 s]: loss = 0.766449 [96.45 s], NDCG = 
[ 0.73066388  0.72133132  0.72238528  0.72558353  0.7320045   0.74082844
  0.75157163  0.76395446  0.77727985  0.7922729 ]
Iteration 3 [94.6 s]: loss = 0.732459 [304.28 s], NDCG = 
[ 0.73273691  0.72408695  0.72403861  0.72805459  0.73462884  0.74294693
  0.75378556  0.76633351  0.77991119  0.79456665]
Iteration 4 [96.3 s]: loss = 0.710392 [379.57 s], NDCG = 
[ 0.73368114  0.72570935  0.72513616  0.72896858  0.73552187  0.74402431
  0.75485645  0.76691371  0.78072994  0.79549633]
Iteration 5 [108.2 s]: loss = 0.692644 [440.29 s], NDCG = 
[ 0.73545609  0.72729772  0.72662993  0.73003885  0.73628748  0.74462558
  0.75545114  0.76773999  0.78123831  0.79637657]
Iteration 6 [108.7 s]: loss = 0.675916 [453.29 s], NDCG = 
[ 0.73681159  0.72909786  0.728899    0.73185814  0.73757664  0.74573308
  0.75652438  0.76883908  0.782289    0.7971037 ]
Iteration 7 [117.9 s]: loss = 0.663951 [472.60 s], NDCG = 
[ 0.73972352  0.73189518  0.73075261  0.73329515  0.73945943  0.74774464
  0.75799728  0.77023471  0.78375941  0.79820811]
Iteration 8 [120.0 s]: loss = 0.657421 [479.89 s], NDCG = 
[ 0.74396674  0.73480966  0.73325633  0.73574025  0.74133661  0.74969154
  0.75985434  0.77177514  0.78516341  0.79958299]
Iteration 9 [121.6 s]: loss = 0.653762 [482.74 s], NDCG = 
[ 0.74830303  0.73783406  0.73555876  0.7370916   0.7428936   0.7511916
  0.76117741  0.77295908  0.7861193   0.8005384 ]
Iteration 10 [121.9 s]: loss = 0.650393 [486.34 s], NDCG = 
[ 0.75100335  0.74006993  0.73734502  0.73900251  0.74396327  0.7521982
  0.76212415  0.77400211  0.78697574  0.80134181]
Iteration 11 [122.7 s]: loss = 0.648214 [488.97 s], NDCG = 
[ 0.75323297  0.74152568  0.73854428  0.7400579   0.74529534  0.7532812
  0.7629354   0.77475284  0.78775864  0.80186553]
Iteration 12 [123.0 s]: loss = 0.646425 [489.49 s], NDCG = 
[ 0.75577921  0.74322225  0.73960441  0.74085364  0.74569507  0.75418605
  0.76394186  0.77549298  0.78854205  0.80270032]
Iteration 13 [122.8 s]: loss = 0.645366 [489.54 s], NDCG = 
[ 0.7564436   0.74492386  0.74073066  0.74165845  0.74651986  0.7547003
  0.76450251  0.77588197  0.78887797  0.80303888]
Iteration 14 [123.1 s]: loss = 0.643539 [489.77 s], NDCG = 
[ 0.75748499  0.74573971  0.74153174  0.74238644  0.74670688  0.75501656
  0.76486298  0.77619779  0.78913691  0.80334652]
Iteration 15 [123.2 s]: loss = 0.642559 [489.69 s], NDCG = 
[ 0.75700108  0.74515957  0.74189732  0.74255221  0.74697293  0.7550703
  0.7650248   0.77625629  0.7893241   0.80333813]
Iteration 16 [123.3 s]: loss = 0.641100 [457.10 s], NDCG = 
[ 0.7579145   0.7455378   0.74222647  0.74279721  0.7473859   0.75512078
  0.76511519  0.77639857  0.78943394  0.80342493]
Iteration 17 [120.1 s]: loss = 0.639847 [480.43 s], NDCG = 
[ 0.75935081  0.7460904   0.74292092  0.74318764  0.7475002   0.75536001
  0.76536762  0.77671268  0.78960702  0.80373655]
Iteration 18 [120.2 s]: loss = 0.639559 [485.52 s], NDCG = 
[ 0.75976995  0.74655181  0.74293589  0.74339533  0.74773903  0.75560847
  0.76549301  0.77690583  0.78976314  0.80382345]
Iteration 19 [116.2 s]: loss = 0.638174 [450.87 s], NDCG = 
[ 0.75970989  0.74683797  0.74286428  0.74344553  0.74797405  0.75574047
  0.76544231  0.77697016  0.78990271  0.80389895]
Iteration 20 [116.8 s]: loss = 0.637361 [449.56 s], NDCG = 
[ 0.7600152   0.74687705  0.74302005  0.74406545  0.7482364   0.75587078
  0.76551961  0.77711289  0.78996688  0.80411093]
Iteration 21 [116.8 s]: loss = 0.636540 [448.91 s], NDCG = 
[ 0.76191278  0.74767704  0.74359583  0.74433148  0.7486079   0.75625948
  0.76580854  0.77746016  0.79016286  0.80441931]
Iteration 22 [118.9 s]: loss = 0.636324 [489.00 s], NDCG = 
[ 0.76301391  0.74815366  0.74387679  0.7446472   0.74860022  0.75629034
  0.76591206  0.7776987   0.79055401  0.80454739]
Iteration 23 [121.6 s]: loss = 0.635483 [485.57 s], NDCG = 
[ 0.76180996  0.74751232  0.74356397  0.74434415  0.74838832  0.75617916
  0.7657059   0.77754156  0.79026295  0.80446903]
Iteration 24 [118.4 s]: loss = 0.635382 [453.59 s], NDCG = 
[ 0.76267779  0.7479647   0.74426431  0.74463407  0.74869298  0.75625178
  0.76591207  0.77761593  0.79046616  0.80474153]
Iteration 25 [116.0 s]: loss = 0.634727 [445.96 s], NDCG = 
[ 0.76175494  0.74775087  0.74392558  0.74429233  0.7486626   0.75643027
  0.76604015  0.77767797  0.79038482  0.80453706]
Iteration 26 [116.6 s]: loss = 0.634051 [448.20 s], NDCG = 
[ 0.76226903  0.74811418  0.74422525  0.74455494  0.74875031  0.75629557
  0.76621263  0.77783015  0.79044184  0.80468863]
Iteration 27 [116.6 s]: loss = 0.633983 [444.21 s], NDCG = 
[ 0.76250548  0.74866341  0.74448128  0.74468258  0.74865235  0.75620333
  0.76628919  0.77773423  0.79048997  0.80477057]
Iteration 28 [116.9 s]: loss = 0.632717 [442.24 s], NDCG = 
[ 0.762774    0.74889398  0.74484685  0.74525502  0.74900351  0.75636318
  0.76646495  0.77779791  0.79060422  0.80484803]
Iteration 29 [116.0 s]: loss = 0.632898 [442.38 s], NDCG = 
[ 0.76214514  0.74817062  0.74432834  0.74482575  0.74869972  0.75631896
  0.76639041  0.77781864  0.79040195  0.8048784 ]
Iteration 30 [116.0 s]: loss = 0.631966 [451.81 s], NDCG = 
[ 0.76288059  0.74848373  0.74466905  0.74487506  0.74914368  0.75657852
  0.76653184  0.77795594  0.79063332  0.80491742]
Iteration 31 [116.4 s]: loss = 0.631737 [474.69 s], NDCG = 
[ 0.76328904  0.74811014  0.74442525  0.74474815  0.74908385  0.75670514
  0.76637565  0.77779428  0.79060325  0.80477991]
Iteration 32 [120.7 s]: loss = 0.631665 [487.34 s], NDCG = 
[ 0.76296549  0.74816635  0.74456501  0.74487493  0.7492934   0.75669185
  0.76645951  0.77778967  0.79072029  0.80486151]
Iteration 33 [123.2 s]: loss = 0.631208 [446.96 s], NDCG = 
[ 0.7627064   0.74796141  0.74463959  0.7448269   0.74920533  0.75663043
  0.76641203  0.77793514  0.79056645  0.80475691]
Iteration 34 [115.8 s]: loss = 0.630421 [442.51 s], NDCG = 
[ 0.76244637  0.74791928  0.7446916   0.74490292  0.74910376  0.7569453
  0.76648864  0.77799359  0.79075314  0.80482877]
Iteration 35 [115.6 s]: loss = 0.630430 [440.82 s], NDCG = 
[ 0.7620722   0.74817757  0.74447806  0.74450699  0.74899141  0.75677347
  0.76637391  0.77777481  0.79053856  0.80478013]
Iteration 36 [115.6 s]: loss = 0.630504 [440.45 s], NDCG = 
[ 0.76255799  0.74773794  0.74458794  0.74476712  0.74895888  0.75686152
  0.76621387  0.77782007  0.79044362  0.80472538]
Iteration 37 [115.6 s]: loss = 0.629891 [439.89 s], NDCG = 
[ 0.76216935  0.74779715  0.74447864  0.74489791  0.74885753  0.75658516
  0.76619822  0.77774465  0.7904586   0.80473969]
Iteration 38 [116.0 s]: loss = 0.629068 [439.72 s], NDCG = 
[ 0.76269194  0.7478755   0.74440254  0.74489436  0.7488474   0.75662252
  0.76623776  0.77772551  0.79059931  0.80473935]
Iteration 39 [115.7 s]: loss = 0.629490 [439.29 s], NDCG = 
[ 0.76243002  0.74775421  0.74448153  0.74455451  0.74874351  0.75669213
  0.76594936  0.77746671  0.79041805  0.80465986]
Iteration 40 [115.6 s]: loss = 0.628653 [439.32 s], NDCG = 
[ 0.76248347  0.74790625  0.74462433  0.74479199  0.74897118  0.7565765
  0.76617268  0.77749549  0.79048514  0.80466324]
Iteration 41 [115.7 s]: loss = 0.628966 [439.79 s], NDCG = 
[ 0.76234512  0.7480675   0.74438684  0.74463593  0.7488688   0.75654729
  0.76611839  0.77753737  0.79036818  0.80466223]
Iteration 42 [116.1 s]: loss = 0.628462 [439.45 s], NDCG = 
[ 0.76277243  0.74830944  0.74431656  0.74478707  0.74896425  0.75674125
  0.7662057   0.77770834  0.79046743  0.80480374]
Iteration 43 [115.7 s]: loss = 0.628135 [439.71 s], NDCG = 
[ 0.76328055  0.74773795  0.74413707  0.74464887  0.74897529  0.75655207
  0.76615469  0.77760094  0.79043722  0.80481481]
Iteration 44 [116.8 s]: loss = 0.627796 [439.69 s], NDCG = 
[ 0.76362233  0.74764861  0.74420714  0.74478159  0.74911952  0.75642763
  0.76615137  0.77786492  0.79058714  0.80489937]
Iteration 45 [116.1 s]: loss = 0.627388 [439.24 s], NDCG = 
[ 0.76332111  0.74793134  0.7440572   0.74472142  0.74893998  0.75641047
  0.76627413  0.7778103   0.79051105  0.80482476]
Iteration 46 [115.9 s]: loss = 0.627544 [439.26 s], NDCG = 
[ 0.76310038  0.74843356  0.7442212   0.74492894  0.74894634  0.75653052
  0.76620974  0.77779999  0.79067055  0.80482486]
Iteration 47 [115.8 s]: loss = 0.627087 [438.68 s], NDCG = 
[ 0.76252623  0.74787313  0.74426673  0.74467901  0.74890982  0.75645845
  0.76622291  0.77761364  0.79047268  0.8046947 ]
Iteration 48 [115.4 s]: loss = 0.626840 [439.51 s], NDCG = 
[ 0.76299913  0.74788143  0.74436327  0.74480538  0.748736    0.75645624
  0.76619024  0.77750184  0.7905678   0.80481971]
Iteration 49 [116.6 s]: loss = 0.626693 [438.26 s], NDCG = 
[ 0.7629353   0.74789518  0.74383786  0.74492449  0.74876454  0.75640176
  0.76607205  0.77763612  0.79050025  0.80464446]
Iteration 50 [115.9 s]: loss = 0.626361 [438.11 s], NDCG = 
[ 0.76197315  0.74794657  0.743931    0.74425456  0.74862621  0.756312
  0.76597135  0.77751255  0.79019971  0.80459905]
Iteration 51 [115.6 s]: loss = 0.626504 [438.87 s], NDCG = 
[ 0.76299599  0.7478358   0.7438878   0.74436306  0.74857244  0.75617342
  0.76597353  0.77739535  0.79036705  0.80462907]
Iteration 52 [115.3 s]: loss = 0.626091 [438.09 s], NDCG = 
[ 0.7623643   0.74774177  0.74376538  0.7441348   0.74828399  0.75605634
  0.76592984  0.77746687  0.79021834  0.80451703]
Iteration 53 [116.4 s]: loss = 0.626014 [438.51 s], NDCG = 
[ 0.76218099  0.74812665  0.74357306  0.74421945  0.74820198  0.7562904
  0.76603162  0.77746917  0.79019068  0.80464027]
Iteration 54 [115.5 s]: loss = 0.625236 [438.39 s], NDCG = 
[ 0.76268628  0.74792506  0.74382417  0.74435911  0.74831191  0.75639689
  0.76609303  0.77759293  0.79024793  0.80464734]
Iteration 55 [115.5 s]: loss = 0.624964 [438.47 s], NDCG = 
[ 0.76312302  0.74810683  0.7441518   0.74401439  0.74807316  0.75626177
  0.76611959  0.77750333  0.79030645  0.80452   ]
Iteration 56 [115.5 s]: loss = 0.624725 [438.64 s], NDCG = 
[ 0.76381162  0.74840825  0.74387052  0.74413891  0.74823959  0.75609677
  0.7660777   0.77752538  0.79028066  0.80456406]
Iteration 57 [115.4 s]: loss = 0.625015 [438.08 s], NDCG = 
[ 0.76322301  0.74806382  0.74380787  0.74399435  0.74798352  0.75607374
  0.76595251  0.77725062  0.79016046  0.80438832]


liurui@ubuntu:~/DeepRec$ KERAS_BACKEND=theano python v3_random_train/MLP.py --learner adam --batch_size_random 1280000 --reg_layers [0.000001,0.001,0.001,0.001] --lr 0.00001
Using Theano backend.
MLP arguments: Namespace(batch_size=256, batch_size_random=1280000, epochs=100, layers='[64,32,16,8]', learner='adam', lr=1e-05, path='Data/yelp/', reg_layers='[0.000001,0.001,0.001,0.001]', verbose=1) 
Load data done [145.1 s]. #user=13679, #item=12922, #train=15651858, #test=316795
Time: [64.3], Init: NDCG = 
[ 0.5607319   0.56661891  0.57407953  0.58435866  0.59709529  0.61099378
  0.62780272  0.64576218  0.6657129   0.68814433]
Iteration 0 [92.4 s]: loss = 0.808634 [62.90 s], NDCG = 
[ 0.68637438  0.68214559  0.68234601  0.68739453  0.69543285  0.70582166
  0.71784938  0.73131759  0.74661386  0.76367505]
Iteration 1 [87.4 s]: loss = 0.758042 [64.10 s], NDCG = 
[ 0.71984814  0.71520695  0.7149171   0.71866059  0.72546069  0.73439457
  0.74566279  0.7578575   0.77181323  0.78721624]
Iteration 2 [87.4 s]: loss = 0.724693 [72.26 s], NDCG = 
[ 0.72725075  0.722495    0.72188966  0.72508676  0.73147961  0.7407787
  0.75135757  0.76367299  0.77760302  0.79244332]
Iteration 3 [89.6 s]: loss = 0.699849 [190.59 s], NDCG = 
[ 0.73339406  0.72650659  0.72546712  0.72881154  0.73512154  0.74376063
  0.75423803  0.76656933  0.78026488  0.7951515 ]
Iteration 4 [100.6 s]: loss = 0.676966 [267.63 s], NDCG = 
[ 0.7378948   0.72988535  0.72902818  0.73167504  0.73752827  0.74614318
  0.75687983  0.76868605  0.78230228  0.79696697]
Iteration 5 [104.6 s]: loss = 0.660523 [292.47 s], NDCG = 
[ 0.74270619  0.73338025  0.73219235  0.73465913  0.74031531  0.74837799
  0.7592949   0.77097819  0.7843168   0.7987379 ]
Iteration 6 [108.2 s]: loss = 0.651870 [304.61 s], NDCG = 
[ 0.74771536  0.73766257  0.7351379   0.73698643  0.74260876  0.75077621
  0.76125441  0.7726936   0.78607176  0.8002839 ]
Iteration 7 [108.8 s]: loss = 0.646867 [319.42 s], NDCG = 
[ 0.75025595  0.74059305  0.73708303  0.7382152   0.74376529  0.75170249
  0.76255327  0.77386984  0.78712063  0.80123161]
Iteration 8 [107.7 s]: loss = 0.644086 [324.89 s], NDCG = 
[ 0.75313423  0.74172198  0.7393275   0.74033965  0.74466684  0.75282424
  0.76329517  0.7746294   0.78780102  0.80210258]
Iteration 9 [108.5 s]: loss = 0.642312 [327.42 s], NDCG = 
[ 0.7561059   0.74350649  0.74074893  0.7414065   0.74591492  0.75374191
  0.76398925  0.77523726  0.78869007  0.80266501]
Iteration 10 [108.7 s]: loss = 0.639804 [328.40 s], NDCG = 
[ 0.75643511  0.74421776  0.74133979  0.74198292  0.74614392  0.7539732
  0.76435829  0.77555548  0.78881442  0.80294796]
Iteration 11 [109.7 s]: loss = 0.638601 [329.22 s], NDCG = 
[ 0.75729948  0.74488763  0.7418849   0.74246434  0.74652083  0.75446996
  0.76462267  0.77623152  0.78926978  0.80306473]
Iteration 12 [109.6 s]: loss = 0.637302 [329.11 s], NDCG = 
[ 0.75804845  0.74542881  0.74203484  0.74276443  0.74649589  0.75469719
  0.76476388  0.77659083  0.78951807  0.80334681]
Iteration 13 [109.3 s]: loss = 0.636509 [330.48 s], NDCG = 
[ 0.76024285  0.7469386   0.74340742  0.74361397  0.74729171  0.7553044
  0.76527198  0.77711237  0.79001815  0.80394107]
Iteration 14 [109.6 s]: loss = 0.635452 [329.27 s], NDCG = 
[ 0.75970863  0.74641321  0.74383556  0.74358474  0.74725854  0.75528019
  0.76543688  0.77703505  0.78971948  0.80399785]
Iteration 15 [109.6 s]: loss = 0.634959 [329.19 s], NDCG = 
[ 0.76071386  0.7469884   0.74373203  0.74385953  0.74764568  0.75585683
  0.7654865   0.77730416  0.79008487  0.80424669]
Iteration 16 [109.7 s]: loss = 0.634685 [329.30 s], NDCG = 
[ 0.76096132  0.74750382  0.74408329  0.74398514  0.7479102   0.75562721
  0.76581867  0.77729239  0.79020703  0.80427186]
Iteration 17 [110.1 s]: loss = 0.633390 [329.37 s], NDCG = 
[ 0.76184172  0.74776763  0.74436807  0.7442587   0.74796126  0.75595587
  0.76578524  0.77741342  0.7903909   0.80441252]
Iteration 18 [110.5 s]: loss = 0.633119 [329.17 s], NDCG = 
[ 0.76246932  0.7481501   0.74445371  0.74451634  0.74819575  0.7558203
  0.76584851  0.7777011   0.79046152  0.80470349]
Iteration 19 [109.9 s]: loss = 0.632346 [329.17 s], NDCG = 
[ 0.76201969  0.74828454  0.74397064  0.74425614  0.74853974  0.75616818
  0.76600954  0.77768798  0.79057817  0.80475715]
Iteration 20 [113.4 s]: loss = 0.632107 [331.63 s], NDCG = 
[ 0.76206622  0.748369    0.7441327   0.74420551  0.74823438  0.75634524
  0.76617272  0.77769223  0.79053319  0.80463549]
Iteration 21 [110.2 s]: loss = 0.631370 [329.13 s], NDCG = 
[ 0.76310604  0.74889751  0.74448028  0.74450081  0.74849705  0.75637658
  0.7662634   0.77785924  0.79057426  0.80489695]
Iteration 22 [109.9 s]: loss = 0.631199 [329.17 s], NDCG = 
[ 0.76133895  0.74867976  0.7444282   0.74446989  0.74865202  0.75629399
  0.76605737  0.7777354   0.79066183  0.80480302]
Iteration 23 [110.2 s]: loss = 0.630640 [328.96 s], NDCG = 
[ 0.76209389  0.74828365  0.74439007  0.7444974   0.74853256  0.75616168
  0.76603525  0.77762988  0.79048128  0.80463458]
Iteration 24 [109.8 s]: loss = 0.630097 [329.18 s], NDCG = 
[ 0.76157414  0.74804068  0.74434678  0.74436662  0.74818889  0.75630158
  0.76616544  0.77747051  0.79040695  0.80442547]
Iteration 25 [110.0 s]: loss = 0.629701 [329.66 s], NDCG = 
[ 0.76152006  0.74851478  0.74474793  0.74427403  0.74831462  0.7562933
  0.76612146  0.77754292  0.79043881  0.80440028]
Iteration 26 [109.8 s]: loss = 0.629571 [328.98 s], NDCG = 
[ 0.7626998   0.74858155  0.7448601   0.74425368  0.74879079  0.75648791
  0.76596544  0.77768934  0.79061124  0.80473   ]
Iteration 27 [109.9 s]: loss = 0.629216 [329.18 s], NDCG = 
[ 0.7629636   0.74902766  0.74532357  0.74461776  0.74905504  0.75669753
  0.76645544  0.77779701  0.79074348  0.8048254 ]
Iteration 28 [109.7 s]: loss = 0.628792 [329.34 s], NDCG = 
[ 0.76272904  0.74929564  0.74545621  0.74471723  0.74916318  0.75667011
  0.76634871  0.77773906  0.79084651  0.80474977]
Iteration 29 [109.9 s]: loss = 0.628433 [328.98 s], NDCG = 
[ 0.76351731  0.74941507  0.74543508  0.74473771  0.74912358  0.75691726
  0.76670278  0.77801744  0.79080124  0.80489975]
Iteration 30 [109.9 s]: loss = 0.628128 [330.91 s], NDCG = 
[ 0.7628982   0.74912239  0.74544734  0.74455842  0.74904987  0.75704525
  0.76650652  0.77791236  0.79072387  0.80484198]
Iteration 31 [114.9 s]: loss = 0.627972 [333.88 s], NDCG = 
[ 0.76229796  0.74921302  0.74539783  0.74483118  0.74897944  0.75700411
  0.76645956  0.77779953  0.79082552  0.8046307 ]
Iteration 32 [110.1 s]: loss = 0.627754 [329.06 s], NDCG = 
[ 0.76219545  0.74919222  0.74514113  0.7444641   0.7488457   0.75660768
  0.76629458  0.77766879  0.79054378  0.8046938 ]
Iteration 33 [109.6 s]: loss = 0.627290 [329.16 s], NDCG = 
[ 0.76281047  0.74926498  0.74560994  0.74496349  0.74906518  0.75682593
  0.76665416  0.77793193  0.79072278  0.80473628]
Iteration 34 [109.8 s]: loss = 0.626936 [328.94 s], NDCG = 
[ 0.76156502  0.7486028   0.74505143  0.74478263  0.74873721  0.75658558
  0.76621085  0.77781084  0.79054017  0.8046085 ]
Iteration 35 [109.8 s]: loss = 0.626758 [328.85 s], NDCG = 
[ 0.7630136   0.74905973  0.74536964  0.74488628  0.74866488  0.75659501
  0.76623324  0.7777795   0.79052156  0.80466524]
Iteration 36 [110.0 s]: loss = 0.626604 [328.83 s], NDCG = 
[ 0.76278249  0.74928461  0.74535135  0.74486849  0.74868314  0.75672859
  0.76626967  0.77777227  0.79053726  0.80475264]
Iteration 37 [109.7 s]: loss = 0.625964 [328.71 s], NDCG = 
[ 0.76247655  0.74887825  0.74507793  0.74490924  0.74884665  0.75650563
  0.76615624  0.7777487   0.7905501   0.80469578]
Iteration 38 [110.0 s]: loss = 0.626070 [328.49 s], NDCG = 
[ 0.76299882  0.7491365   0.74510226  0.74491075  0.74892083  0.7564623
  0.76615376  0.7777572   0.7905583   0.80464211]
Iteration 39 [110.0 s]: loss = 0.625415 [328.34 s], NDCG = 
[ 0.76336576  0.74861582  0.74528122  0.74489083  0.74880141  0.75656168
  0.76610971  0.77759024  0.79050877  0.80464899]
Iteration 40 [109.6 s]: loss = 0.625088 [328.11 s], NDCG = 
[ 0.76374464  0.74877513  0.74502077  0.74448115  0.74893746  0.75659486
  0.76627999  0.77777125  0.79055036  0.80469005]
Iteration 41 [110.1 s]: loss = 0.624576 [327.85 s], NDCG = 
[ 0.76311421  0.74861927  0.74499595  0.74445966  0.74879521  0.75648573
  0.76630139  0.77764432  0.79048874  0.80469584]
Iteration 42 [110.2 s]: loss = 0.624452 [327.53 s], NDCG = 
[ 0.76297303  0.74858144  0.74451075  0.74454604  0.74903454  0.75649855
  0.76632678  0.77759378  0.79036317  0.80464729]
Iteration 43 [110.0 s]: loss = 0.623737 [327.59 s], NDCG = 
[ 0.764343    0.74946465  0.74472833  0.7446286   0.749063    0.75662814
  0.76635425  0.77764649  0.79049918  0.80470348]
Iteration 44 [110.3 s]: loss = 0.623834 [327.26 s], NDCG = 
[ 0.76376351  0.74855467  0.74441232  0.744278    0.74874688  0.75634285
  0.76589648  0.77741728  0.79003673  0.80453587]
Iteration 45 [110.1 s]: loss = 0.623354 [327.33 s], NDCG = 
[ 0.7640575   0.74900714  0.74463753  0.7447674   0.74883046  0.75654773
  0.76628657  0.77738434  0.7902539   0.80454144]
Iteration 46 [110.1 s]: loss = 0.623494 [327.44 s], NDCG = 
[ 0.76539382  0.74954352  0.74463676  0.74464096  0.74893157  0.75663046
  0.76631498  0.77755933  0.79025477  0.8045596 ]
Iteration 47 [110.1 s]: loss = 0.622956 [327.18 s], NDCG = 
[ 0.76480333  0.74945981  0.74484684  0.74462186  0.7487327   0.75660154
  0.76622856  0.77770339  0.79017419  0.80448982]
Iteration 48 [109.9 s]: loss = 0.622481 [326.62 s], NDCG = 
[ 0.76462442  0.74849848  0.74431428  0.7444582   0.74885821  0.7566446
  0.76613964  0.77764481  0.79024632  0.80450959]
Iteration 49 [110.3 s]: loss = 0.622695 [326.69 s], NDCG = 
[ 0.76450776  0.74834245  0.74454204  0.74427446  0.74881691  0.75645553
  0.76614092  0.77743542  0.79015866  0.80444929]
Iteration 50 [109.9 s]: loss = 0.622504 [326.47 s], NDCG = 
[ 0.76457096  0.74849934  0.74404048  0.74424553  0.74858903  0.75635931
  0.76627231  0.77729482  0.79022754  0.8044846 ]
Iteration 51 [110.0 s]: loss = 0.622023 [326.65 s], NDCG = 
[ 0.76543344  0.74853436  0.74387375  0.74441559  0.7488089   0.75641148
  0.76622451  0.77744914  0.79029999  0.80451675]
Iteration 52 [110.1 s]: loss = 0.621419 [326.87 s], NDCG = 
[ 0.76377672  0.74853734  0.74401404  0.74398838  0.74868764  0.75615788
  0.76595675  0.77741175  0.79010036  0.80438803]
Iteration 53 [110.4 s]: loss = 0.621497 [326.81 s], NDCG = 
[ 0.7638113   0.74893733  0.74383466  0.74402995  0.74812468  0.75596144
  0.76595932  0.77741859  0.79004556  0.80425574]
Iteration 54 [110.1 s]: loss = 0.621392 [326.65 s], NDCG = 
[ 0.76302963  0.7485686   0.74334737  0.74384002  0.74811597  0.75573453
  0.76573454  0.77711587  0.79004012  0.80406557]
Iteration 55 [110.1 s]: loss = 0.620853 [327.31 s], NDCG = 
[ 0.76393739  0.74858034  0.74366104  0.74400573  0.74816335  0.75583303
  0.76576105  0.77711788  0.78998933  0.80418222]
Iteration 56 [110.0 s]: loss = 0.620579 [326.55 s], NDCG = 
[ 0.76398455  0.74914515  0.74370046  0.74427309  0.74787055  0.75573591
  0.76558201  0.77706178  0.78995702  0.80419431]
Iteration 57 [110.3 s]: loss = 0.620252 [326.42 s], NDCG = 
[ 0.76414554  0.74842552  0.74366111  0.7439754   0.74767193  0.75558635
  0.76540941  0.77670561  0.78954118  0.80400143]
Iteration 58 [110.3 s]: loss = 0.619589 [327.80 s], NDCG = 
[ 0.76368081  0.74854359  0.74373334  0.74364075  0.74785144  0.75561681
  0.76542358  0.77663997  0.78967636  0.80381485]
Iteration 59 [110.0 s]: loss = 0.619737 [326.60 s], NDCG = 
[ 0.76327897  0.74857174  0.74387553  0.74375546  0.74789846  0.75562905
  0.76534904  0.77662044  0.78985696  0.80375582]
Iteration 60 [110.3 s]: loss = 0.619214 [326.54 s], NDCG = 
[ 0.76304189  0.74791769  0.74379694  0.74351791  0.74770528  0.75562474
  0.76534778  0.77666515  0.78955229  0.80358659]
Iteration 61 [110.3 s]: loss = 0.619175 [326.33 s], NDCG = 
[ 0.76265483  0.74818597  0.74397636  0.74352452  0.74762613  0.75561384
  0.76522462  0.77675768  0.78957279  0.80376726]
Iteration 62 [109.8 s]: loss = 0.618407 [326.79 s], NDCG = 
[ 0.76364811  0.74816853  0.7435846   0.74303689  0.74728826  0.7553525
  0.76511177  0.77655663  0.78963     0.80356485]
Iteration 63 [109.7 s]: loss = 0.617962 [327.27 s], NDCG = 
[ 0.76459675  0.74842828  0.74365078  0.7434516   0.7473923   0.75554911
  0.76515814  0.77652204  0.78973322  0.80359311]
Iteration 64 [109.7 s]: loss = 0.618576 [327.22 s], NDCG = 
[ 0.76462913  0.74902275  0.7435753   0.74333065  0.74751058  0.75552061
  0.76506578  0.77663401  0.78970551  0.80360083]
Iteration 65 [109.6 s]: loss = 0.618598 [327.22 s], NDCG = 
[ 0.76531396  0.74862506  0.74348328  0.74330627  0.74746565  0.75531841
  0.76517299  0.77658671  0.78978888  0.80358298]
Iteration 66 [109.7 s]: loss = 0.618210 [326.94 s], NDCG = 
[ 0.76510235  0.74840524  0.74337902  0.74297086  0.74720911  0.7550761
  0.76487927  0.77661078  0.78960421  0.80352074]
Iteration 67 [109.6 s]: loss = 0.617479 [326.89 s], NDCG = 
[ 0.76276425  0.74796343  0.74248648  0.74250894  0.74706338  0.75457945
  0.76471204  0.77627781  0.7892649   0.80325764]
Iteration 68 [109.8 s]: loss = 0.617934 [328.14 s], NDCG = 
[ 0.76394776  0.74816181  0.74290691  0.74296226  0.74727877  0.75479956
  0.76458044  0.77630935  0.78933733  0.80327133]
Iteration 69 [109.6 s]: loss = 0.617464 [326.97 s], NDCG = 
[ 0.76454329  0.74794588  0.7429822   0.74297491  0.74709189  0.75475667
  0.76481352  0.77642031  0.7892419   0.80334285]
Iteration 70 [109.7 s]: loss = 0.616871 [326.79 s], NDCG = 
[ 0.76452506  0.74814094  0.74292338  0.74266804  0.74676093  0.75483814
  0.76469475  0.77640797  0.7892549   0.80334109]
Iteration 71 [109.7 s]: loss = 0.617144 [329.71 s], NDCG = 
[ 0.76441595  0.74801453  0.74298189  0.74254076  0.7466186   0.75471235
  0.76440494  0.77619113  0.78919041  0.80326993]
Iteration 72 [110.1 s]: loss = 0.617253 [327.07 s], NDCG = 
[ 0.76529792  0.74813267  0.7429522   0.74260991  0.74678077  0.75463889
  0.76443533  0.77619568  0.78922012  0.80312257]
Iteration 73 [109.8 s]: loss = 0.617059 [328.25 s], NDCG = 
[ 0.76423767  0.74781117  0.74265594  0.74232329  0.74662563  0.75452589
  0.76427829  0.77584072  0.78905753  0.80290051]



