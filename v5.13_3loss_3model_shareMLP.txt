liurui@ubuntu:~/DeepRec$ KERAS_BACKEND=theano python v5.13_3loss/MLP.py --learner adam --reg_layers [0,0,0,0] --lr 0.0001 --batch_size_random 1280000
Using Theano backend.
MLP arguments: Namespace(batch_size=256, batch_size_random=1280000, epochs=100, layers='[64,32,16,8]', learner='adam', lr=0.0001, path='Data/yelp/', reg_layers='[0,0,0,0]', verbose=1) 
Load data done [137.2 s]. #user=13679, #item=12922, #train_rating=323348, #train_rank=15651858, #test=316795
Time: [108.1], Init: 
NDCG_rank: [ 0.5518066   0.5582596   0.56704646  0.57778076  0.59022482  0.60597592
  0.62335266  0.64165977  0.662273    0.68490641]
NDCG_rating1: [ 0.56268836  0.56753304  0.5763633   0.58657925  0.59886202  0.61331305
  0.62991824  0.64825242  0.66883899  0.69074244]
NDCG_rating2: [ 0.55976786  0.56627716  0.57315397  0.5841868   0.59660925  0.6111452
  0.6269058   0.64549424  0.66575018  0.68816219]
Iteration 0 [14.5 s]: rank_loss = 6.213602 [106.62 s],
NDCG_rank: [ 0.54718167  0.55719729  0.5667166   0.5774181   0.59029927  0.60571231
  0.62303576  0.64155557  0.66213137  0.6849771 ]
NDCG_rating1: [ 0.70703363  0.69993244  0.69800584  0.70098065  0.70690957  0.71616818
  0.72753865  0.74098016  0.75555204  0.77201525]
NDCG_rating2: [ 0.56977021  0.56932719  0.57513021  0.58465161  0.59733541  0.61157577
  0.62804913  0.64633216  0.6664972   0.68873581]
Iteration 0 [14.9 s]: rank_loss = 3.189666 [110.20 s],
NDCG_rank: [ 0.54718167  0.55719729  0.5667166   0.5774181   0.59029927  0.60571231
  0.62303576  0.64155557  0.66213137  0.6849771 ]
NDCG_rating1: [ 0.70707136  0.69994097  0.69801238  0.70099878  0.70692284  0.71617772
  0.72755251  0.74098258  0.75555433  0.77201935]
NDCG_rating2: [ 0.73008658  0.71967332  0.71719872  0.71946319  0.7260239   0.73448125
  0.74549489  0.758136    0.77229233  0.7874745 ]
Iteration 0 [102.1 s]: rank_loss = 0.651901 [108.75 s],
NDCG_rank: [ 0.75546007  0.74132753  0.7382298   0.73871761  0.74337945  0.75122838
  0.76161652  0.77334731  0.78626585  0.80059462]
NDCG_rating1: [ 0.3752479   0.39729683  0.41738874  0.43645399  0.45685392  0.47875598
  0.50187186  0.52696954  0.55407868  0.58293329]
NDCG_rating2: [ 0.75900808  0.74355832  0.73950674  0.73995154  0.7453543   0.75299665
  0.76283656  0.7743639   0.78772082  0.80184061]
Iteration 1 [12.9 s]: rank_loss = 1.388112 [107.46 s],
NDCG_rank: [ 0.54711092  0.55717946  0.56668746  0.57738722  0.59028528  0.60568903
  0.62302064  0.6415425   0.66211841  0.68496425]
NDCG_rating1: [ 0.76173764  0.74869751  0.74475605  0.74529668  0.74987236  0.75771804
  0.76791899  0.77925436  0.79218771  0.80592887]
NDCG_rating2: [ 0.75901752  0.743555    0.73952793  0.73997136  0.74535781  0.75299286
  0.7628405   0.77436521  0.78772663  0.80182647]
Iteration 1 [12.9 s]: rank_loss = 1.118062 [107.97 s],
NDCG_rank: [ 0.54718167  0.55719729  0.5667166   0.5774181   0.59029927  0.60571231
  0.62303576  0.64155557  0.66213137  0.6849771 ]
NDCG_rating1: [ 0.76197346  0.74869253  0.74481077  0.74532803  0.74981608  0.757732
  0.76794389  0.77925588  0.79225202  0.80593538]
NDCG_rating2: [ 0.76751842  0.75450668  0.74978198  0.7503238   0.75473513  0.76182588
  0.77150748  0.78271709  0.79508699  0.80864361]
Iteration 1 [101.9 s]: rank_loss = 0.618757 [106.47 s],
NDCG_rank: [ 0.76115375  0.74572311  0.74124771  0.7420925   0.74587543  0.75306761
  0.76358908  0.77555001  0.78834456  0.80263556]
NDCG_rating1: [ 0.55107066  0.56780645  0.58259255  0.59612866  0.60997829  0.62582019
  0.64273154  0.66100308  0.68047103  0.70097258]
NDCG_rating2: [ 0.76066185  0.74491076  0.74003392  0.74059929  0.7453364   0.75294784
  0.76306189  0.774613    0.78771072  0.80195029]
Iteration 2 [12.6 s]: rank_loss = 1.078598 [109.74 s],
NDCG_rank: [ 0.73591673  0.72219757  0.71578253  0.71565296  0.72015628  0.72738277
  0.7382803   0.75118989  0.7655674   0.7820308 ]
NDCG_rating1: [ 0.77520877  0.75885384  0.75325274  0.75274509  0.756845    0.76457352
  0.7738209   0.78481459  0.79724369  0.81073984]
NDCG_rating2: [ 0.76062411  0.74490222  0.74000221  0.74059929  0.74535116  0.7529731
  0.76304084  0.77460284  0.78770486  0.80193934]
Iteration 2 [13.1 s]: rank_loss = 1.007893 [110.30 s],
NDCG_rank: [ 0.66086179  0.64966791  0.64713003  0.64898907  0.65654457  0.66747036
  0.68115827  0.69611447  0.71355528  0.73359102]
NDCG_rating1: [ 0.77537385  0.75881426  0.75333201  0.75265576  0.75692371  0.76449887
  0.77384525  0.78479194  0.79722905  0.81074226]
NDCG_rating2: [ 0.76971534  0.75399034  0.75034192  0.74988953  0.75407325  0.76086503
  0.7708675   0.78230716  0.79492551  0.80838352]
Iteration 2 [103.2 s]: rank_loss = 0.603086 [110.40 s],
NDCG_rank: [ 0.76262622  0.74748858  0.74323702  0.74444133  0.74917404  0.75662823
  0.76583954  0.77717491  0.7901555   0.80405137]
NDCG_rating1: [ 0.75846852  0.74463661  0.74072404  0.74131536  0.74578082  0.75327415
  0.7628642   0.77452039  0.78743094  0.80156006]
NDCG_rating2: [ 0.76300731  0.74790368  0.74264674  0.74356945  0.74816838  0.75562582
  0.76494741  0.77674801  0.78995233  0.80390493]
Iteration 3 [12.9 s]: rank_loss = 0.995742 [113.61 s],
NDCG_rank: [ 0.76459958  0.75024259  0.74425372  0.74441329  0.74796349  0.7551729
  0.76468348  0.77571029  0.78883883  0.80323852]
NDCG_rating1: [ 0.77657272  0.75913871  0.75401555  0.75363563  0.75762703  0.76470008
  0.7742039   0.78522008  0.79788567  0.81141258]
NDCG_rating2: [ 0.76284695  0.74775387  0.74268472  0.74352025  0.74816483  0.75561169
  0.76492923  0.77678715  0.78995045  0.80385697]
Iteration 3 [13.1 s]: rank_loss = 0.959974 [113.96 s],
NDCG_rank: [ 0.76558594  0.74952533  0.74245446  0.74213486  0.74557487  0.75216915
  0.7608263   0.77223814  0.78565609  0.80052601]
NDCG_rating1: [ 0.7766246   0.75902609  0.75397758  0.75356596  0.75760875  0.76465854
  0.77412944  0.78517711  0.79788381  0.81137275]
NDCG_rating2: [ 0.77196256  0.75526605  0.75081845  0.75119087  0.75535642  0.76220206
  0.77144311  0.78281946  0.79585161  0.80921704]
Iteration 3 [105.2 s]: rank_loss = 0.589936 [103.84 s],
NDCG_rank: [ 0.76404277  0.74809752  0.74261763  0.7423181   0.74732164  0.75458736
  0.76420627  0.77533654  0.7886488   0.80263876]
NDCG_rating1: [ 0.77018698  0.75466126  0.74989171  0.7500008   0.754002    0.76142357
  0.77136566  0.78244793  0.79515659  0.80895129]
NDCG_rating2: [ 0.75693258  0.74251957  0.73719383  0.73691652  0.74129718  0.74911605
  0.75870521  0.77058922  0.78386895  0.79867105]
Iteration 4 [12.2 s]: rank_loss = 0.957072 [102.17 s],
NDCG_rank: [ 0.76471659  0.75059893  0.74533582  0.74485721  0.75010356  0.75728573
  0.76664527  0.77782395  0.79082892  0.80484964]
NDCG_rating1: [ 0.77656616  0.7586607   0.7528139   0.75230017  0.7565938   0.76373826
  0.77332435  0.78456704  0.79691802  0.81056108]
NDCG_rating2: [ 0.75742309  0.74269766  0.73727682  0.7371132   0.74142972  0.74921909
  0.75882645  0.77063723  0.78400892  0.79881351]
Iteration 4 [12.3 s]: rank_loss = 0.934006 [101.74 s],
NDCG_rank: [ 0.76614252  0.75059265  0.74495394  0.74526759  0.75006795  0.75649163
  0.76595594  0.77710956  0.78990752  0.80420647]
NDCG_rating1: [ 0.77662622  0.75890374  0.75307553  0.75237641  0.7567941   0.76387072
  0.77335277  0.78460097  0.79695787  0.8105958 ]
NDCG_rating2: [ 0.77114132  0.75454987  0.74873821  0.74814055  0.75227349  0.75944074
  0.76907457  0.78038378  0.79328153  0.80720009]
Iteration 4 [98.6 s]: rank_loss = 0.581079 [102.10 s],
NDCG_rank: [ 0.75799347  0.74302962  0.73899316  0.73950006  0.74364165  0.75107508
  0.76066     0.77246448  0.78586544  0.79998059]
NDCG_rating1: [ 0.77079922  0.75564247  0.74970665  0.75041246  0.75433487  0.76158105
  0.7713837   0.78268302  0.79529879  0.80909565]
NDCG_rating2: [ 0.7351002   0.7234109   0.71841709  0.72028707  0.72558945  0.73411863
  0.74469557  0.75720344  0.77123987  0.78657724]
Iteration 5 [12.2 s]: rank_loss = 0.928370 [102.46 s],
NDCG_rank: [ 0.76237373  0.74801542  0.74338232  0.74404554  0.74822483  0.75532281
  0.76413104  0.77576388  0.78909636  0.80352434]
NDCG_rating1: [ 0.77108787  0.75467374  0.7481466   0.74785993  0.75174998  0.75941773
  0.76934239  0.78072317  0.79334107  0.80737874]
NDCG_rating2: [ 0.73479363  0.72303248  0.71814692  0.7201802   0.72548302  0.73380865
  0.74455453  0.75718827  0.7711214   0.78649829]
Iteration 5 [12.3 s]: rank_loss = 0.916250 [102.26 s],
NDCG_rank: [ 0.76570138  0.74923936  0.74354066  0.74422067  0.74857832  0.75545087
  0.76488786  0.77600849  0.78925418  0.80343805]
NDCG_rating1: [ 0.7710168   0.75495144  0.74835124  0.74804506  0.75186181  0.75956979
  0.76940675  0.78082922  0.79344974  0.80744606]
NDCG_rating2: [ 0.76481752  0.74979384  0.74474061  0.74465171  0.74897885  0.75600383
  0.76554732  0.77735268  0.79051445  0.80468035]
Iteration 5 [98.9 s]: rank_loss = 0.575003 [102.14 s],
NDCG_rank: [ 0.75483094  0.73931959  0.73471412  0.73510722  0.73996483  0.7475326
  0.75732265  0.76903614  0.78292048  0.79733414]
NDCG_rating1: [ 0.7705461   0.75464464  0.74851273  0.7483297   0.75226634  0.75997658
  0.7698984   0.78083809  0.79359206  0.80735496]
NDCG_rating2: [ 0.74010465  0.72765823  0.72502185  0.72683074  0.73184271  0.74007584
  0.75017584  0.76232079  0.77651385  0.79159975]
Iteration 6 [12.2 s]: rank_loss = 0.909364 [102.32 s],
NDCG_rank: [ 0.76248634  0.7465874   0.74150348  0.74179213  0.74582717  0.75340295
  0.76288889  0.77471011  0.78769466  0.80202862]
NDCG_rating1: [ 0.76699809  0.75138467  0.74605104  0.74584801  0.74989561  0.7571997
  0.7670751   0.77886972  0.79143515  0.80553752]
NDCG_rating2: [ 0.73949026  0.72746077  0.72469018  0.72666071  0.73171095  0.73982995
  0.74997764  0.7622356   0.77637002  0.79147585]
Iteration 6 [12.3 s]: rank_loss = 0.899932 [102.59 s],
NDCG_rank: [ 0.76349692  0.74723812  0.74232148  0.74276393  0.74673948  0.75409017
  0.76349898  0.77473555  0.78820675  0.80215044]
NDCG_rating1: [ 0.76699368  0.75125908  0.74590223  0.74544661  0.7499779   0.75726821
  0.7670882   0.77885706  0.79131062  0.80556396]
NDCG_rating2: [ 0.7605677   0.74761197  0.74253814  0.74264565  0.74647738  0.75384711
  0.76363459  0.77548074  0.78850758  0.80303923]
Iteration 6 [98.7 s]: rank_loss = 0.569004 [102.66 s],
NDCG_rank: [ 0.74833515  0.73324717  0.72924775  0.73039627  0.73556247  0.74339412
  0.7536654   0.76600112  0.7797381   0.79439721]
NDCG_rating1: [ 0.76767379  0.75190631  0.74593076  0.74591372  0.75043043  0.75769739
  0.76756581  0.7785633   0.79164136  0.80588735]
NDCG_rating2: [ 0.73503574  0.72690589  0.72328055  0.72538694  0.73157096  0.74030563
  0.75069611  0.76332172  0.77721523  0.79207669]
Iteration 7 [12.2 s]: rank_loss = 0.894824 [102.86 s],
NDCG_rank: [ 0.75626819  0.74214654  0.73714803  0.73716178  0.7410877   0.74903404
  0.7588073   0.77056515  0.78400467  0.79868174]
NDCG_rating1: [ 0.76242692  0.74615541  0.74159151  0.74180716  0.74602719  0.7535324
  0.76358635  0.77518421  0.78860378  0.80293225]
NDCG_rating2: [ 0.73576553  0.72666221  0.72328792  0.72569493  0.73170114  0.7401561
  0.75078979  0.76332083  0.77713686  0.79209594]
Iteration 7 [12.3 s]: rank_loss = 0.884901 [102.74 s],
NDCG_rank: [ 0.75695994  0.74297261  0.73756711  0.73810799  0.74205581  0.7495988
  0.7594753   0.77100653  0.78466761  0.79917969]
NDCG_rating1: [ 0.76249798  0.7460221   0.74180101  0.74164488  0.74612452  0.75366539
  0.76347871  0.77512215  0.78862369  0.80290213]
NDCG_rating2: [ 0.75694044  0.74354358  0.73882737  0.73998817  0.74488893  0.75230325
  0.76244173  0.77382705  0.78730509  0.80177837]
Iteration 7 [98.8 s]: rank_loss = 0.561838 [102.85 s],
NDCG_rank: [ 0.74222202  0.72797704  0.72422162  0.72580274  0.73104482  0.73910313
  0.75030188  0.76255105  0.7767079   0.79196246]
NDCG_rating1: [ 0.75739071  0.74320434  0.73917916  0.73933556  0.74412579  0.75170332
  0.76191665  0.77373562  0.78714078  0.80150098]
NDCG_rating2: [ 0.73477099  0.72646547  0.72365762  0.72699727  0.73327022  0.7419671
  0.7524884   0.76509813  0.77907297  0.79391201]
Iteration 8 [12.2 s]: rank_loss = 0.882071 [103.06 s],
NDCG_rank: [ 0.75020349  0.73369182  0.72905651  0.73028697  0.73508758  0.74320571
  0.75359607  0.76592933  0.77993529  0.79482145]
NDCG_rating1: [ 0.75270351  0.74043962  0.73636876  0.73709843  0.74169888  0.74953404
  0.7600322   0.77178253  0.78506331  0.79970026]
NDCG_rating2: [ 0.73437355  0.72613509  0.72365759  0.72680734  0.73322242  0.74180189
  0.75243811  0.76496993  0.77903905  0.79394695]
Iteration 8 [12.3 s]: rank_loss = 0.866880 [103.46 s],
NDCG_rank: [ 0.73912458  0.72826632  0.72595463  0.72753471  0.73265677  0.74062495
  0.75180405  0.76403851  0.77795705  0.79320881]
NDCG_rating1: [ 0.75290789  0.74050552  0.73660065  0.73696205  0.7417631   0.74957167
  0.75995152  0.77195132  0.78517893  0.79971943]
NDCG_rating2: [ 0.75218345  0.73839396  0.73443657  0.73519024  0.74026979  0.74852032
  0.75915445  0.77117289  0.78445533  0.79921623]
Iteration 8 [98.6 s]: rank_loss = 0.551982 [103.00 s],
NDCG_rank: [ 0.73237976  0.72083259  0.719568    0.72189877  0.72756743  0.73675015
  0.74773873  0.76015703  0.77418958  0.78948643]
NDCG_rating1: [ 0.74115485  0.73035728  0.72618863  0.72843811  0.73356424  0.74251437
  0.75321353  0.76533415  0.77943873  0.79440651]
NDCG_rating2: [ 0.72286702  0.71619392  0.71629738  0.71969923  0.72624884  0.73591439
  0.74703886  0.75952668  0.77379258  0.78883405]
Iteration 9 [12.2 s]: rank_loss = 0.867558 [103.20 s],
NDCG_rank: [ 0.72827547  0.71820695  0.71628463  0.71903552  0.72560364  0.73469743
  0.74562109  0.7582401   0.77244217  0.78791127]
NDCG_rating1: [ 0.74811568  0.73827859  0.73414196  0.73518284  0.74038361  0.74844753
  0.75870325  0.77076824  0.78419011  0.79879106]
NDCG_rating2: [ 0.72395369  0.71678537  0.71636964  0.71980855  0.72638882  0.73604297
  0.74719927  0.75962352  0.77405842  0.78896975]
Iteration 9 [12.4 s]: rank_loss = 0.840971 [103.42 s],
NDCG_rank: [ 0.72825131  0.71769832  0.71619776  0.71918037  0.72533938  0.73426056
  0.74537406  0.75825134  0.77220062  0.78772486]
NDCG_rating1: [ 0.74792702  0.73815902  0.73398834  0.73527553  0.74046605  0.74830399
  0.75864995  0.77076333  0.78422855  0.79877947]
NDCG_rating2: [ 0.74032129  0.72908156  0.72645329  0.72815322  0.73423894  0.74304068
  0.75330763  0.76538756  0.77930931  0.79417676]
Iteration 9 [98.6 s]: rank_loss = 0.539429 [103.54 s],
NDCG_rank: [ 0.72593522  0.7170528   0.71463054  0.71843757  0.72417273  0.7331185
  0.74484643  0.75766573  0.771528    0.78701915]
NDCG_rating1: [ 0.7368588   0.72708396  0.72392709  0.72564757  0.73157601  0.74051399
  0.75206709  0.76416886  0.7780418   0.79325215]
NDCG_rating2: [ 0.72096756  0.7148279   0.71309326  0.71670471  0.72299193  0.73163073
  0.7432081   0.75578135  0.77052218  0.78573628]
Iteration 10 [12.2 s]: rank_loss = 0.850470 [103.17 s],
NDCG_rank: [ 0.72550477  0.71728781  0.71562845  0.71890735  0.72531425  0.73385713
  0.74487296  0.75797969  0.77163518  0.78728596]
NDCG_rating1: [ 0.74178748  0.73225507  0.7284845   0.73020182  0.73551243  0.74385987
  0.75518499  0.76746457  0.78103689  0.79591731]
NDCG_rating2: [ 0.72051258  0.71470974  0.71363927  0.71677866  0.72281571  0.73144361
  0.74311791  0.75575541  0.77041568  0.78567255]
Iteration 10 [12.3 s]: rank_loss = 0.806105 [103.40 s],
NDCG_rank: [ 0.7249388   0.71558483  0.71436736  0.71786241  0.72424487  0.73308835
  0.7442743   0.75741209  0.77145112  0.78692719]
NDCG_rating1: [ 0.74185194  0.73239965  0.72853696  0.73006761  0.73580049  0.74405528
  0.75538019  0.76752881  0.78091139  0.79583451]
NDCG_rating2: [ 0.72917038  0.71996067  0.71713405  0.71973125  0.72589123  0.73506131
  0.74659227  0.7592309   0.77323109  0.78833341]
Iteration 10 [98.3 s]: rank_loss = 0.526248 [110.64 s],
NDCG_rank: [ 0.72050597  0.71196473  0.70991171  0.7136189   0.72056053  0.72982318
  0.74144677  0.75423205  0.76848676  0.78417014]
NDCG_rating1: [ 0.73446128  0.72392276  0.7221018   0.72407844  0.73003034  0.73883832
  0.75031914  0.76316308  0.77735939  0.79215788]
NDCG_rating2: [ 0.71297351  0.70694533  0.70535144  0.70854271  0.7151351   0.72572974
  0.73720191  0.75019805  0.76462346  0.78034056]
Iteration 11 [12.8 s]: rank_loss = 0.828035 [109.24 s],
NDCG_rank: [ 0.72186022  0.71323661  0.71205423  0.71504587  0.72132738  0.73051387
  0.74191932  0.75500511  0.76908855  0.78476058]
NDCG_rating1: [ 0.73847528  0.72814883  0.72574514  0.72728333  0.73309892  0.74182822
  0.7528815   0.76564857  0.77924712  0.79418973]
NDCG_rating2: [ 0.7127204   0.70713511  0.70534213  0.70871363  0.71532426  0.72546728
  0.73714143  0.75021883  0.76466594  0.78021159]
Iteration 11 [12.7 s]: rank_loss = 0.768138 [109.00 s],
NDCG_rank: [ 0.71996799  0.71062186  0.71056391  0.71349896  0.71981103  0.7292759
  0.74100384  0.75387132  0.76840223  0.78418659]
NDCG_rating1: [ 0.73805363  0.72833186  0.7252366   0.72727985  0.73306173  0.7417293
  0.75277778  0.76549666  0.77916762  0.79411291]
NDCG_rating2: [ 0.71693123  0.7098005   0.70882648  0.71165764  0.71818396  0.72816269
  0.73992069  0.7528414   0.76747355  0.78310631]


liurui@ubuntu:~/DeepRec$ KERAS_BACKEND=theano python v5.13_3loss/MLP0.py --learner adam --reg_layers [0,0,0,0] --lr 0.0001 --batch_size_random 1280000
Using Theano backend.
MLP arguments: Namespace(batch_size=256, batch_size_random=1280000, epochs=100, layers='[64,32,16,8]', learner='adam', lr=0.0001, path='Data/yelp/', reg_layers='[0,0,0,0]', verbose=1) 
Load data done [140.5 s]. #user=13679, #item=12922, #train_rating=323348, #train_rank=15651858, #test=316795
Time: [109.8], Init: 
NDCG_rank: [ 0.55391849  0.56044297  0.56867491  0.5794915   0.59249529  0.60714641
  0.62439307  0.64336953  0.66366867  0.68646972]
NDCG_rating1: [ 0.56429379  0.56707395  0.57460505  0.58379565  0.59684405  0.61056248
  0.62747507  0.64573325  0.66590062  0.68806515]
NDCG_rating2: [ 0.56481467  0.57006598  0.57684482  0.58692862  0.59952756  0.61387919
  0.62989374  0.64791721  0.6677589   0.69000908]
Iteration 0 [99.4 s]: rank_loss = 0.636475 [108.24 s],
NDCG_rank: [ 0.75088072  0.73836941  0.73516153  0.73544933  0.73995034  0.74838405
  0.75857821  0.7705349   0.78394277  0.79830403]
NDCG_rating1: [ 0.69520068  0.6932523   0.6960782   0.70197947  0.71054969  0.72111802
  0.73390758  0.74762153  0.76227108  0.77814349]
NDCG_rating2: [ 0.37167073  0.39446665  0.4141389   0.43424252  0.45490321  0.47615644
  0.49971944  0.52504779  0.55247064  0.58176571]
Iteration 1 [101.6 s]: rank_loss = 0.595753 [108.00 s],
NDCG_rank: [ 0.75557263  0.74320584  0.73725771  0.73752409  0.74204091  0.74942923
  0.7592552   0.77153538  0.78484741  0.79907747]
NDCG_rating1: [ 0.63451367  0.63673824  0.64339105  0.65162972  0.66263752  0.67576632
  0.69121391  0.70800413  0.72594188  0.74391606]
NDCG_rating2: [ 0.37433385  0.39754075  0.41686076  0.43697757  0.45674771  0.47816789
  0.50210336  0.52707966  0.55398846  0.58331778]
Iteration 2 [101.8 s]: rank_loss = 0.566727 [108.06 s],
NDCG_rank: [ 0.73402701  0.7215772   0.71932865  0.72055396  0.72590612  0.73423603
  0.74506526  0.75734897  0.77144877  0.78648995]
NDCG_rating1: [ 0.60015061  0.60546535  0.61402158  0.62393137  0.63695378  0.65136694
  0.66750803  0.68569492  0.70481125  0.72447762]
NDCG_rating2: [ 0.37574793  0.40097443  0.42091109  0.44177582  0.46323839  0.48503372
  0.50785824  0.53299317  0.55954192  0.58818043]


liurui@ubuntu:~/DeepRec$ KERAS_BACKEND=theano python v5.13_3loss/MLP0.py --learner adam --reg_layers [0,0,0,0] --lr 0.00001 --batch_size_random 1280000
Using Theano backend.
MLP arguments: Namespace(batch_size=256, batch_size_random=1280000, epochs=100, layers='[64,32,16,8]', learner='adam', lr=1e-05, path='Data/yelp/', reg_layers='[0,0,0,0]', verbose=1) 
Load data done [138.1 s]. #user=13679, #item=12922, #train_rating=323348, #train_rank=15651858, #test=316795
Time: [109.9], Init: 
NDCG_rank: [ 0.55427173  0.56166397  0.56958683  0.57912644  0.59209142  0.6077885
  0.62467227  0.64306494  0.66361463  0.68621746]
NDCG_rating1: [ 0.56344573  0.5687205   0.57626332  0.58653624  0.59878684  0.61413545
  0.6301811   0.64874775  0.66798124  0.68991619]
NDCG_rating2: [ 0.56140729  0.56712046  0.57527138  0.58479663  0.59707844  0.61143648
  0.62818229  0.64677196  0.66681436  0.6889326 ]
Iteration 0 [103.6 s]: rank_loss = 0.692495 [108.75 s],
NDCG_rank: [ 0.68591653  0.67886257  0.67843142  0.68331796  0.69066616  0.70058757
  0.71232064  0.72649397  0.74221978  0.75931788]
NDCG_rating1: [ 0.48364337  0.49182322  0.50251777  0.51538722  0.53005694  0.54679703
  0.56566969  0.58672275  0.61028959  0.63574747]
NDCG_rating2: [ 0.61152189  0.61938454  0.62775411  0.6391954   0.65136747  0.66480782
  0.67997678  0.69662878  0.71431179  0.7335023 ]
Iteration 1 [105.3 s]: rank_loss = 0.682935 [114.92 s],
NDCG_rank: [ 0.72397754  0.71680625  0.71614352  0.7190359   0.72582692  0.73390157
  0.74456799  0.75677687  0.77099914  0.78651572]
NDCG_rating1: [ 0.41535687  0.43153971  0.44609327  0.46142037  0.47828537  0.49773162
  0.51912861  0.54305341  0.56919597  0.59751075]
NDCG_rating2: [ 0.65613475  0.65978875  0.6679714   0.6771246   0.6880804   0.70012295
  0.71440647  0.72958108  0.74625526  0.76304205]



