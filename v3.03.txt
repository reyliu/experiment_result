liurui@ubuntu:~/DeepRec$ KERAS_BACKEND=theano python v3.03_eval_paircomp_rand/MLP.py --learner adam --reg_layers [0,0,0,0] --lr 0.00001 --batch_size_random 1280000
Using Theano backend.
MLP arguments: Namespace(batch_size=256, batch_size_random=1280000, epochs=100, layers='[64,32,16,8]', learner='adam', lr=1e-05, path='Data/yelp/', reg_layers='[0,0,0,0]', verbose=1) 
Load data done [143.9 s]. #user=13679, #item=12922, #train=15651858, #test=316795
Time: [66.1], Init: NDCG = 
[ 0.56460481  0.56662787  0.57426186  0.58400815  0.59583771  0.61037118
  0.62697386  0.64544999  0.66577812  0.6880894 ]
Iteration 0 [100.7 s]: loss = 0.692389 [65.32 s], NDCG = 
[ 0.65006569  0.65256579  0.65907444  0.66663548  0.67681909  0.68939807
  0.70308063  0.71782892  0.73449588  0.75201805]
Iteration 1 [102.6 s]: loss = 0.680146 [65.24 s], NDCG = 
[ 0.718809    0.71238321  0.71323984  0.71722455  0.72379213  0.73286892
  0.74424866  0.7568038   0.77113802  0.78654074]
Iteration 2 [101.2 s]: loss = 0.647328 [65.42 s], NDCG = 
[ 0.73628492  0.72836205  0.72772951  0.72997115  0.73554107  0.74392059
  0.75424591  0.76651293  0.77993173  0.79470516]
Iteration 3 [100.4 s]: loss = 0.625387 [68.52 s], NDCG = 
[ 0.75170453  0.73845783  0.73553602  0.73622654  0.74153209  0.74951326
  0.75972641  0.77152077  0.78493555  0.79935871]
Iteration 4 [103.6 s]: loss = 0.618258 [69.47 s], NDCG = 
[ 0.75426838  0.74155953  0.73859143  0.73940431  0.74399029  0.751564
  0.76174503  0.77354706  0.78681093  0.80095529]
Iteration 5 [101.0 s]: loss = 0.614565 [65.69 s], NDCG = 
[ 0.75583329  0.74461589  0.7409168   0.7414063   0.74546212  0.75314524
  0.76332345  0.77494419  0.78797175  0.80241537]
Iteration 6 [99.9 s]: loss = 0.612553 [65.86 s], NDCG = 
[ 0.75765478  0.74540796  0.74178038  0.74217263  0.74610689  0.7539535
  0.76355927  0.77553106  0.78841146  0.80269401]
Iteration 7 [121.7 s]: loss = 0.610785 [111.95 s], NDCG = 
[ 0.75868296  0.74536991  0.74152072  0.74150238  0.74564041  0.75360149
  0.7635807   0.77521605  0.78826406  0.80274889]
Iteration 8 [101.6 s]: loss = 0.608702 [69.34 s], NDCG = 
[ 0.76022618  0.74670496  0.74226792  0.74126894  0.74583179  0.75370602
  0.76361066  0.77537483  0.7884917   0.80281836]
Iteration 9 [104.6 s]: loss = 0.606421 [70.92 s], NDCG = 
[ 0.76107325  0.74708962  0.74258918  0.74181066  0.7465099   0.75381871
  0.76371677  0.77557546  0.78875369  0.80292035]
Iteration 10 [103.6 s]: loss = 0.605153 [69.70 s], NDCG = 
[ 0.76134115  0.7470151   0.74244029  0.74165132  0.74581676  0.75347095
  0.76373487  0.77552971  0.78858968  0.80268759]
Iteration 11 [100.4 s]: loss = 0.603780 [65.51 s], NDCG = 
[ 0.76422541  0.7478649   0.74311357  0.74273397  0.74658775  0.75393435
  0.76412079  0.77574412  0.78874346  0.80285254]

