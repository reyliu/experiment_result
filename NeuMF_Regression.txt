liurui@ubuntu:~/NeuMF_Regression$ KERAS_BACKEND=theano python NeuMF.py --learner adam --dataset yelp --reg_layers [0,0,0,0] --lr 0.0001
Using Theano backend.
NeuMF arguments: Namespace(batch_size=256, dataset='yelp', epochs=100, layers='[64,32,16,8]', learner='adam', lr=0.0001, mf_pretrain='', mlp_pretrain='', num_factors=8, num_neg=4, out=1, path='Data/', reg_layers='[0,0,0,0]', reg_mf=0, verbose=1) 
Load data done [4.3 s]. #user=13679, #item=12922, #train=323348, #test=316795
Init: NDCG = 0.690145
WARNING (theano.tensor.blas): We did not found a dynamic library into the library_dir of the library we use for blas. If you use ATLAS, make sure to compile it with dynamics library.
Iteration 0 [26.0 s]: NDCG = 0.760200, loss = 7.3147 [22.5 s]
Iteration 1 [17.4 s]: NDCG = 0.797641, loss = 1.1372 [22.0 s]
Iteration 2 [17.3 s]: NDCG = 0.807206, loss = 1.0068 [22.0 s]
Iteration 3 [17.0 s]: NDCG = 0.810404, loss = 0.9785 [21.7 s]
Iteration 4 [17.2 s]: NDCG = 0.811122, loss = 0.9679 [21.6 s]
Iteration 5 [17.8 s]: NDCG = 0.811452, loss = 0.9618 [22.4 s]
Iteration 6 [17.0 s]: NDCG = 0.811421, loss = 0.9565 [22.3 s]
Iteration 7 [17.1 s]: NDCG = 0.811601, loss = 0.9512 [21.7 s]
Iteration 8 [16.9 s]: NDCG = 0.811621, loss = 0.9455 [22.7 s]
Iteration 9 [17.4 s]: NDCG = 0.811552, loss = 0.9392 [18.8 s]
Iteration 10 [16.0 s]: NDCG = 0.811339, loss = 0.9318 [18.5 s]
Iteration 11 [15.9 s]: NDCG = 0.811405, loss = 0.9236 [18.2 s]
Iteration 12 [15.9 s]: NDCG = 0.811124, loss = 0.9141 [18.3 s]
Iteration 13 [15.9 s]: NDCG = 0.810920, loss = 0.9034 [18.2 s]
Iteration 14 [16.0 s]: NDCG = 0.810829, loss = 0.8912 [18.3 s]
Iteration 15 [15.9 s]: NDCG = 0.810747, loss = 0.8770 [18.3 s]
Iteration 16 [15.9 s]: NDCG = 0.810514, loss = 0.8607 [18.3 s]
Iteration 17 [15.9 s]: NDCG = 0.809694, loss = 0.8413 [18.2 s]
Iteration 18 [15.9 s]: NDCG = 0.808966, loss = 0.8186 [18.3 s]
Iteration 19 [15.9 s]: NDCG = 0.807981, loss = 0.7933 [18.2 s]
Iteration 20 [15.9 s]: NDCG = 0.806564, loss = 0.7663 [18.2 s]
Iteration 21 [16.0 s]: NDCG = 0.805180, loss = 0.7392 [18.2 s]
Iteration 22 [16.0 s]: NDCG = 0.802900, loss = 0.7122 [18.3 s]
Iteration 23 [16.1 s]: NDCG = 0.800668, loss = 0.6855 [18.3 s]
Iteration 24 [15.9 s]: NDCG = 0.798372, loss = 0.6589 [18.3 s]
Iteration 25 [16.0 s]: NDCG = 0.795590, loss = 0.6326 [18.3 s]
Iteration 26 [15.9 s]: NDCG = 0.793112, loss = 0.6060 [18.2 s]
Iteration 27 [15.9 s]: NDCG = 0.790467, loss = 0.5798 [18.3 s]
Iteration 28 [16.0 s]: NDCG = 0.787271, loss = 0.5539 [18.3 s]
Iteration 29 [15.9 s]: NDCG = 0.784465, loss = 0.5286 [18.3 s]
Iteration 30 [15.9 s]: NDCG = 0.781523, loss = 0.5042 [18.2 s]
Iteration 31 [16.0 s]: NDCG = 0.778710, loss = 0.4804 [18.2 s]
Iteration 32 [16.0 s]: NDCG = 0.776278, loss = 0.4576 [18.2 s]
Iteration 33 [15.9 s]: NDCG = 0.774724, loss = 0.4355 [18.2 s]
Iteration 34 [15.9 s]: NDCG = 0.772428, loss = 0.4149 [18.3 s]
Iteration 35 [15.9 s]: NDCG = 0.770150, loss = 0.3952 [18.3 s]
Iteration 36 [16.0 s]: NDCG = 0.767423, loss = 0.3767 [18.2 s]
Iteration 37 [16.0 s]: NDCG = 0.766026, loss = 0.3594 [18.3 s]
Iteration 38 [15.9 s]: NDCG = 0.763945, loss = 0.3430 [18.3 s]
Iteration 39 [16.0 s]: NDCG = 0.762984, loss = 0.3276 [18.2 s]
Iteration 40 [16.0 s]: NDCG = 0.761624, loss = 0.3130 [18.3 s]
Iteration 41 [16.0 s]: NDCG = 0.760383, loss = 0.2991 [18.2 s]
Iteration 42 [15.9 s]: NDCG = 0.757847, loss = 0.2862 [18.2 s]
Iteration 43 [16.0 s]: NDCG = 0.757446, loss = 0.2740 [18.4 s]
Iteration 44 [16.0 s]: NDCG = 0.755866, loss = 0.2622 [18.3 s]
Iteration 45 [16.0 s]: NDCG = 0.754632, loss = 0.2512 [18.4 s]
Iteration 46 [16.0 s]: NDCG = 0.754984, loss = 0.2409 [18.2 s]
Iteration 47 [15.9 s]: NDCG = 0.753378, loss = 0.2306 [18.3 s]
Iteration 48 [16.0 s]: NDCG = 0.752680, loss = 0.2214 [18.3 s]
Iteration 49 [16.0 s]: NDCG = 0.751653, loss = 0.2127 [18.3 s]
Iteration 50 [16.0 s]: NDCG = 0.750281, loss = 0.2043 [18.3 s]
Iteration 51 [15.9 s]: NDCG = 0.749961, loss = 0.1966 [18.2 s]
Iteration 52 [15.9 s]: NDCG = 0.749319, loss = 0.1892 [18.2 s]
Iteration 53 [16.0 s]: NDCG = 0.748091, loss = 0.1823 [18.3 s]
Iteration 54 [15.9 s]: NDCG = 0.747430, loss = 0.1757 [18.2 s]
Iteration 55 [15.9 s]: NDCG = 0.747195, loss = 0.1696 [18.2 s]
Iteration 56 [16.0 s]: NDCG = 0.746435, loss = 0.1636 [18.3 s]
Iteration 57 [16.0 s]: NDCG = 0.746203, loss = 0.1581 [18.3 s]
Iteration 58 [15.9 s]: NDCG = 0.745133, loss = 0.1528 [18.4 s]
Iteration 59 [16.0 s]: NDCG = 0.744422, loss = 0.1477 [18.2 s]
Iteration 60 [16.0 s]: NDCG = 0.745006, loss = 0.1431 [18.3 s]
Iteration 61 [15.9 s]: NDCG = 0.744546, loss = 0.1385 [18.3 s]
Iteration 62 [15.9 s]: NDCG = 0.744090, loss = 0.1342 [18.2 s]
Iteration 63 [16.0 s]: NDCG = 0.743476, loss = 0.1301 [18.5 s]
Iteration 64 [16.0 s]: NDCG = 0.742314, loss = 0.1262 [18.2 s]
Iteration 65 [16.0 s]: NDCG = 0.742165, loss = 0.1225 [18.2 s]
Iteration 66 [16.0 s]: NDCG = 0.742169, loss = 0.1189 [18.3 s]
Iteration 67 [16.0 s]: NDCG = 0.741458, loss = 0.1155 [18.3 s]
Iteration 68 [15.9 s]: NDCG = 0.741299, loss = 0.1123 [18.2 s]
Iteration 69 [16.0 s]: NDCG = 0.740338, loss = 0.1092 [18.3 s]
Iteration 70 [15.9 s]: NDCG = 0.739957, loss = 0.1063 [18.3 s]
Iteration 71 [16.0 s]: NDCG = 0.740746, loss = 0.1033 [18.2 s]
Iteration 72 [15.9 s]: NDCG = 0.740107, loss = 0.1007 [18.3 s]
Iteration 73 [16.0 s]: NDCG = 0.739326, loss = 0.0981 [18.2 s]
Iteration 74 [15.9 s]: NDCG = 0.739759, loss = 0.0953 [18.3 s]
Iteration 75 [16.0 s]: NDCG = 0.739624, loss = 0.0930 [18.3 s]
Iteration 76 [15.9 s]: NDCG = 0.738954, loss = 0.0907 [18.3 s]
Iteration 77 [16.0 s]: NDCG = 0.738229, loss = 0.0883 [18.2 s]
Iteration 78 [16.0 s]: NDCG = 0.737993, loss = 0.0861 [18.2 s]
Iteration 79 [15.9 s]: NDCG = 0.737629, loss = 0.0841 [18.3 s]
Iteration 80 [15.9 s]: NDCG = 0.738300, loss = 0.0821 [18.2 s]
Iteration 81 [16.0 s]: NDCG = 0.737596, loss = 0.0801 [18.3 s]
Iteration 82 [16.0 s]: NDCG = 0.738073, loss = 0.0781 [18.3 s]
Iteration 83 [15.9 s]: NDCG = 0.737463, loss = 0.0764 [18.3 s]
Iteration 84 [15.9 s]: NDCG = 0.737264, loss = 0.0745 [18.2 s]
Iteration 85 [16.0 s]: NDCG = 0.737904, loss = 0.0727 [18.2 s]
Iteration 86 [15.9 s]: NDCG = 0.737749, loss = 0.0712 [18.3 s]
Iteration 87 [15.9 s]: NDCG = 0.737457, loss = 0.0695 [18.3 s]
Iteration 88 [16.0 s]: NDCG = 0.737040, loss = 0.0680 [18.3 s]
Iteration 89 [16.0 s]: NDCG = 0.736919, loss = 0.0665 [18.3 s]
Iteration 90 [15.9 s]: NDCG = 0.735911, loss = 0.0651 [18.3 s]
Iteration 91 [16.0 s]: NDCG = 0.735697, loss = 0.0636 [18.2 s]
Iteration 92 [15.9 s]: NDCG = 0.736624, loss = 0.0622 [18.2 s]
Iteration 93 [15.9 s]: NDCG = 0.735777, loss = 0.0610 [18.4 s]
Iteration 94 [16.0 s]: NDCG = 0.736155, loss = 0.0596 [18.3 s]
Iteration 95 [15.9 s]: NDCG = 0.735495, loss = 0.0583 [18.3 s]
Iteration 96 [16.0 s]: NDCG = 0.735923, loss = 0.0572 [18.2 s]
Iteration 97 [15.9 s]: NDCG = 0.735738, loss = 0.0560 [18.3 s]
Iteration 98 [16.0 s]: NDCG = 0.735316, loss = 0.0548 [18.6 s]
Iteration 99 [16.0 s]: NDCG = 0.734849, loss = 0.0537 [18.2 s]
End. Best Iteration 8:  NDCG = 0.811621. 
The best NeuMF model is saved to Pretrain/yelp_NeuMF_8_[64,32,16,8]_1511528701.h5
liurui@ubuntu:~/NeuMF_Regression$ KERAS_BACKEND=theano python NeuMF.py --learner adam --dataset yelp --reg_layers [0.00001,0.0001,0.001,0.01] --lr 0.0001
Using Theano backend.
NeuMF arguments: Namespace(batch_size=256, dataset='yelp', epochs=100, layers='[64,32,16,8]', learner='adam', lr=0.0001, mf_pretrain='', mlp_pretrain='', num_factors=8, num_neg=4, out=1, path='Data/', reg_layers='[0.00001,0.0001,0.001,0.01]', reg_mf=0, verbose=1) 
Load data done [4.4 s]. #user=13679, #item=12922, #train=323348, #test=316795
Init: NDCG = 0.689081
Iteration 0 [22.1 s]: NDCG = 0.766302, loss = 6.9453 [19.0 s]
Iteration 1 [18.3 s]: NDCG = 0.801015, loss = 1.1964 [19.0 s]
Iteration 2 [18.4 s]: NDCG = 0.808193, loss = 1.0772 [19.0 s]
Iteration 3 [18.4 s]: NDCG = 0.810321, loss = 1.0455 [19.1 s]
Iteration 4 [18.5 s]: NDCG = 0.811259, loss = 1.0306 [19.2 s]
Iteration 5 [18.6 s]: NDCG = 0.811797, loss = 1.0202 [19.2 s]
Iteration 6 [18.8 s]: NDCG = 0.811681, loss = 1.0109 [19.3 s]
Iteration 7 [19.3 s]: NDCG = 0.811855, loss = 1.0023 [19.5 s]
Iteration 8 [20.3 s]: NDCG = 0.811616, loss = 0.9934 [22.1 s]
Iteration 9 [21.1 s]: NDCG = 0.811727, loss = 0.9846 [23.1 s]
Iteration 10 [21.8 s]: NDCG = 0.811519, loss = 0.9750 [23.0 s]
Iteration 11 [22.0 s]: NDCG = 0.811842, loss = 0.9649 [22.7 s]
Iteration 12 [21.9 s]: NDCG = 0.811344, loss = 0.9539 [22.7 s]
Iteration 13 [22.0 s]: NDCG = 0.811657, loss = 0.9420 [22.7 s]
Iteration 14 [21.9 s]: NDCG = 0.811182, loss = 0.9293 [22.8 s]
Iteration 15 [22.1 s]: NDCG = 0.810766, loss = 0.9157 [22.7 s]
Iteration 16 [22.0 s]: NDCG = 0.810692, loss = 0.9010 [22.7 s]
Iteration 17 [21.9 s]: NDCG = 0.810233, loss = 0.8855 [22.7 s]
Iteration 18 [22.1 s]: NDCG = 0.809694, loss = 0.8692 [22.7 s]
Iteration 19 [22.2 s]: NDCG = 0.808875, loss = 0.8522 [22.7 s]
Iteration 20 [21.9 s]: NDCG = 0.807932, loss = 0.8346 [22.7 s]
Iteration 21 [21.9 s]: NDCG = 0.806336, loss = 0.8164 [22.7 s]
Iteration 22 [22.0 s]: NDCG = 0.805040, loss = 0.7978 [22.6 s]
Iteration 23 [22.0 s]: NDCG = 0.803719, loss = 0.7790 [22.7 s]
Iteration 24 [21.9 s]: NDCG = 0.802045, loss = 0.7600 [22.7 s]
Iteration 25 [21.9 s]: NDCG = 0.800208, loss = 0.7410 [22.6 s]
Iteration 26 [22.0 s]: NDCG = 0.798649, loss = 0.7223 [22.7 s]
Iteration 27 [22.0 s]: NDCG = 0.797447, loss = 0.7035 [22.7 s]
Iteration 28 [22.0 s]: NDCG = 0.794957, loss = 0.6851 [23.0 s]
Iteration 29 [21.9 s]: NDCG = 0.792997, loss = 0.6670 [22.7 s]
Iteration 30 [22.0 s]: NDCG = 0.790966, loss = 0.6492 [22.7 s]
Iteration 31 [22.0 s]: NDCG = 0.788776, loss = 0.6318 [22.7 s]
Iteration 32 [22.2 s]: NDCG = 0.786822, loss = 0.6149 [22.8 s]
Iteration 33 [22.0 s]: NDCG = 0.785302, loss = 0.5985 [22.8 s]
Iteration 34 [22.0 s]: NDCG = 0.783747, loss = 0.5827 [22.7 s]
Iteration 35 [22.0 s]: NDCG = 0.782032, loss = 0.5676 [22.7 s]
Iteration 36 [22.0 s]: NDCG = 0.780233, loss = 0.5531 [22.7 s]
Iteration 37 [21.9 s]: NDCG = 0.778394, loss = 0.5396 [22.8 s]
Iteration 38 [22.0 s]: NDCG = 0.776620, loss = 0.5267 [22.7 s]
Iteration 39 [21.9 s]: NDCG = 0.774988, loss = 0.5147 [22.7 s]
Iteration 40 [22.0 s]: NDCG = 0.772596, loss = 0.5034 [22.8 s]
Iteration 41 [21.9 s]: NDCG = 0.771544, loss = 0.4927 [22.7 s]
Iteration 42 [22.0 s]: NDCG = 0.771417, loss = 0.4828 [22.8 s]
Iteration 43 [21.9 s]: NDCG = 0.769104, loss = 0.4735 [22.8 s]
Iteration 44 [21.9 s]: NDCG = 0.768286, loss = 0.4647 [22.8 s]
Iteration 45 [21.9 s]: NDCG = 0.767181, loss = 0.4564 [22.7 s]
Iteration 46 [22.0 s]: NDCG = 0.766456, loss = 0.4485 [22.6 s]
Iteration 47 [21.9 s]: NDCG = 0.764741, loss = 0.4410 [22.8 s]
Iteration 48 [21.9 s]: NDCG = 0.764573, loss = 0.4341 [22.7 s]
Iteration 49 [21.9 s]: NDCG = 0.762275, loss = 0.4273 [22.6 s]
Iteration 50 [22.0 s]: NDCG = 0.761818, loss = 0.4209 [22.7 s]
Iteration 51 [21.9 s]: NDCG = 0.761495, loss = 0.4148 [22.7 s]
Iteration 52 [22.0 s]: NDCG = 0.760307, loss = 0.4089 [22.8 s]
Iteration 53 [22.0 s]: NDCG = 0.759755, loss = 0.4034 [22.8 s]
Iteration 54 [22.0 s]: NDCG = 0.759204, loss = 0.3981 [22.6 s]
Iteration 55 [22.0 s]: NDCG = 0.759344, loss = 0.3928 [22.7 s]
Iteration 56 [22.0 s]: NDCG = 0.757893, loss = 0.3880 [22.6 s]
Iteration 57 [22.0 s]: NDCG = 0.757280, loss = 0.3832 [22.6 s]
Iteration 58 [22.1 s]: NDCG = 0.756432, loss = 0.3785 [22.8 s]
Iteration 59 [22.0 s]: NDCG = 0.756976, loss = 0.3742 [22.8 s]
Iteration 60 [22.1 s]: NDCG = 0.755461, loss = 0.3699 [22.7 s]
Iteration 61 [22.0 s]: NDCG = 0.755396, loss = 0.3658 [22.8 s]
Iteration 62 [22.0 s]: NDCG = 0.754843, loss = 0.3617 [22.7 s]
Iteration 63 [22.2 s]: NDCG = 0.754477, loss = 0.3579 [22.6 s]
Iteration 64 [22.1 s]: NDCG = 0.754423, loss = 0.3543 [22.7 s]
Iteration 65 [22.0 s]: NDCG = 0.754261, loss = 0.3506 [22.6 s]
Iteration 66 [22.1 s]: NDCG = 0.753548, loss = 0.3471 [22.7 s]
Iteration 67 [22.0 s]: NDCG = 0.753062, loss = 0.3437 [22.7 s]
Iteration 68 [22.1 s]: NDCG = 0.752300, loss = 0.3404 [22.8 s]
Iteration 69 [22.0 s]: NDCG = 0.752598, loss = 0.3373 [22.8 s]
Iteration 70 [22.1 s]: NDCG = 0.751488, loss = 0.3342 [22.7 s]
Iteration 71 [22.0 s]: NDCG = 0.750638, loss = 0.3312 [22.6 s]
Iteration 72 [22.1 s]: NDCG = 0.750700, loss = 0.3282 [22.7 s]
Iteration 73 [22.0 s]: NDCG = 0.749993, loss = 0.3253 [22.8 s]
Iteration 74 [22.1 s]: NDCG = 0.750402, loss = 0.3226 [22.7 s]
Iteration 75 [22.0 s]: NDCG = 0.749407, loss = 0.3198 [22.6 s]
Iteration 76 [22.0 s]: NDCG = 0.749239, loss = 0.3172 [22.8 s]
Iteration 77 [22.0 s]: NDCG = 0.748681, loss = 0.3147 [22.7 s]
Iteration 78 [22.0 s]: NDCG = 0.748658, loss = 0.3122 [22.7 s]
Iteration 79 [22.7 s]: NDCG = 0.748019, loss = 0.3097 [22.6 s]
Iteration 80 [22.0 s]: NDCG = 0.747224, loss = 0.3073 [22.6 s]
Iteration 81 [22.0 s]: NDCG = 0.747611, loss = 0.3050 [22.7 s]
Iteration 82 [22.1 s]: NDCG = 0.746725, loss = 0.3027 [22.7 s]
Iteration 83 [22.0 s]: NDCG = 0.748476, loss = 0.3005 [22.8 s]
Iteration 84 [22.0 s]: NDCG = 0.746360, loss = 0.2983 [22.8 s]
Iteration 85 [22.0 s]: NDCG = 0.746675, loss = 0.2963 [22.7 s]
Iteration 86 [22.1 s]: NDCG = 0.745941, loss = 0.2941 [22.7 s]
Iteration 87 [22.0 s]: NDCG = 0.745717, loss = 0.2921 [22.6 s]
Iteration 88 [22.0 s]: NDCG = 0.745199, loss = 0.2901 [22.7 s]
Iteration 89 [22.0 s]: NDCG = 0.745254, loss = 0.2882 [22.8 s]
Iteration 90 [22.0 s]: NDCG = 0.744185, loss = 0.2863 [22.7 s]
Iteration 91 [22.0 s]: NDCG = 0.745258, loss = 0.2844 [22.8 s]
Iteration 92 [22.3 s]: NDCG = 0.744487, loss = 0.2825 [22.5 s]
Iteration 93 [22.0 s]: NDCG = 0.744047, loss = 0.2807 [22.6 s]
Iteration 94 [22.0 s]: NDCG = 0.744712, loss = 0.2789 [22.7 s]
Iteration 95 [22.1 s]: NDCG = 0.742601, loss = 0.2772 [22.9 s]
Iteration 96 [22.0 s]: NDCG = 0.742803, loss = 0.2755 [22.7 s]
Iteration 97 [22.0 s]: NDCG = 0.743777, loss = 0.2738 [22.7 s]
Iteration 98 [22.1 s]: NDCG = 0.743476, loss = 0.2722 [22.7 s]
Iteration 99 [22.0 s]: NDCG = 0.742632, loss = 0.2705 [22.8 s]
End. Best Iteration 7:  NDCG = 0.811855. 
The best NeuMF model is saved to Pretrain/yelp_NeuMF_8_[64,32,16,8]_1511541127.h5


liurui@ubuntu:~/NeuMF_Regression$ KERAS_BACKEND=theano python MLP.py --learner adam --reg_layers [0,0,0,0] --lr 0.00001
Using Theano backend.
MLP arguments: Namespace(batch_size=256, dataset='yelp', epochs=100, layers='[64,32,16,8]', learner='adam', lr=1e-05, out=1, path='Data/', reg_layers='[0,0,0,0]', verbose=1) 
Load data done [4.1 s]. #user=13679, #item=12922, #train=323348, #test=316795
Init: NDCG = 
[ 0.56263231  0.56675254  0.57421994  0.58489463  0.59783596  0.61270752
  0.62904454  0.64740391  0.66714809  0.68925586]
Iteration 0 [16.4 s]: loss = 15.4291 [20.2 s], NDCG = 
[ 0.57763992  0.57991992  0.58702765  0.59627219  0.60812361  0.62258321
  0.63806488  0.65592037  0.67547957  0.69708015]
Iteration 1 [13.6 s]: loss = 14.6571 [22.1 s], NDCG = 
[ 0.59384222  0.5973179   0.60462381  0.61325733  0.62449194  0.63782672
  0.65271442  0.6695388   0.68821061  0.70878234]
Iteration 2 [13.8 s]: loss = 13.4793 [21.6 s], NDCG = 
[ 0.60445483  0.60772101  0.61482861  0.62288984  0.63340993  0.6455582
  0.66044132  0.67666372  0.69512909  0.71553472]
Iteration 3 [14.1 s]: loss = 11.8218 [23.0 s], NDCG = 
[ 0.6099413   0.61254673  0.61918629  0.62743983  0.63705094  0.64917378
  0.66423522  0.68021281  0.69829759  0.71826457]
Iteration 4 [13.7 s]: loss = 9.6478 [23.2 s], NDCG = 
[ 0.61039408  0.61556942  0.62080957  0.62935231  0.6390244   0.65167053
  0.6661609   0.68201451  0.70014489  0.71990773]
Iteration 5 [14.3 s]: loss = 7.1383 [23.1 s], NDCG = 
[ 0.61236088  0.61779219  0.62333116  0.6315006   0.64136828  0.65377066
  0.66841542  0.68429408  0.70202378  0.72167112]
Iteration 6 [14.3 s]: loss = 4.6858 [21.8 s], NDCG = 
[ 0.6160485   0.62158039  0.62706498  0.63444634  0.64455957  0.65703013
  0.67141502  0.68711404  0.70481235  0.72432415]
Iteration 7 [13.7 s]: loss = 2.7880 [21.1 s], NDCG = 
[ 0.62391017  0.62819     0.63330849  0.6401237   0.65010257  0.66232663
  0.67648157  0.69198283  0.70937511  0.72881143]
Iteration 8 [13.5 s]: loss = 1.7655 [20.6 s], NDCG = 
[ 0.6381243   0.64035254  0.64372688  0.65030128  0.65950922  0.67111447
  0.68456883  0.69993634  0.71711582  0.73605516]
Iteration 9 [13.6 s]: loss = 1.4204 [20.7 s], NDCG = 
[ 0.65575151  0.65436081  0.65732071  0.66286282  0.67131325  0.6820991
  0.69489482  0.70975571  0.72656511  0.74458471]
Iteration 10 [13.5 s]: loss = 1.3091 [20.7 s], NDCG = 
[ 0.67021996  0.66717545  0.66854776  0.67399815  0.68209724  0.69221316
  0.70437692  0.71931369  0.73583703  0.75278365]
Iteration 11 [13.6 s]: loss = 1.2390 [20.9 s], NDCG = 
[ 0.68777261  0.68088537  0.68093577  0.68539154  0.69246942  0.70264608
  0.71482022  0.72892002  0.7446777   0.76113499]
Iteration 12 [13.6 s]: loss = 1.1846 [20.8 s], NDCG = 
[ 0.70031204  0.69299756  0.6915828   0.69494348  0.70173503  0.71117325
  0.72329862  0.73693224  0.75230265  0.76860846]
Iteration 13 [13.6 s]: loss = 1.1417 [20.7 s], NDCG = 
[ 0.71260747  0.70270281  0.70117368  0.70330564  0.71011484  0.71907605
  0.73085952  0.74436204  0.75906352  0.77528915]
Iteration 14 [13.6 s]: loss = 1.1068 [20.8 s], NDCG = 
[ 0.72210166  0.71106469  0.70929496  0.71189723  0.71741669  0.72605368
  0.73756121  0.75087794  0.76513507  0.78115559]
Iteration 15 [13.6 s]: loss = 1.0778 [20.5 s], NDCG = 
[ 0.72987057  0.71842434  0.71555177  0.71760939  0.72345439  0.73185897
  0.74320398  0.75633386  0.77039591  0.785719  ]
Iteration 16 [13.6 s]: loss = 1.0531 [20.9 s], NDCG = 
[ 0.73680939  0.7249028   0.72095075  0.72278133  0.72851508  0.73717551
  0.74836304  0.76091175  0.77482887  0.78982898]
Iteration 17 [13.6 s]: loss = 1.0321 [20.8 s], NDCG = 
[ 0.74175505  0.72962506  0.72513795  0.727008    0.73239678  0.74085877
  0.75200549  0.76464346  0.77823276  0.79317134]
Iteration 18 [13.6 s]: loss = 1.0140 [21.0 s], NDCG = 
[ 0.74643784  0.73360302  0.72919652  0.73080438  0.7359492   0.74421279
  0.75533121  0.76762953  0.78119088  0.79574957]
Iteration 19 [13.6 s]: loss = 0.9987 [20.8 s], NDCG = 
[ 0.75111529  0.73704178  0.73264013  0.73394329  0.73897696  0.74728218
  0.75787996  0.77014519  0.78367312  0.79809925]
Iteration 20 [13.6 s]: loss = 0.9856 [20.6 s], NDCG = 
[ 0.75466928  0.74055219  0.73586532  0.73673207  0.74167913  0.75003595
  0.76065427  0.77260654  0.78575198  0.80014685]
Iteration 21 [13.6 s]: loss = 0.9746 [20.7 s], NDCG = 
[ 0.75822075  0.74292223  0.73829558  0.73921628  0.74391002  0.75232712
  0.76262322  0.77455497  0.78753194  0.80185214]
Iteration 22 [13.6 s]: loss = 0.9653 [21.2 s], NDCG = 
[ 0.75955991  0.7450302   0.73983999  0.74080698  0.74578179  0.75413794
  0.76417126  0.77603553  0.78869382  0.80304196]
Iteration 23 [13.8 s]: loss = 0.9575 [21.0 s], NDCG = 
[ 0.76299347  0.74678612  0.7416459   0.74232267  0.74759387  0.75552583
  0.76580455  0.77736094  0.7900033   0.80424983]
Iteration 24 [13.7 s]: loss = 0.9510 [21.0 s], NDCG = 
[ 0.76425999  0.74879136  0.74312927  0.74430713  0.74891953  0.75708881
  0.76712867  0.77874032  0.79131382  0.80536767]
Iteration 25 [13.8 s]: loss = 0.9456 [20.9 s], NDCG = 
[ 0.76437696  0.74984729  0.74519701  0.745694    0.75043403  0.75823207
  0.7683216   0.77969422  0.79220034  0.80627323]
Iteration 26 [13.7 s]: loss = 0.9411 [22.3 s], NDCG = 
[ 0.76639434  0.75147507  0.7471349   0.74666078  0.7518191   0.75951114
  0.7694095   0.78078352  0.79331329  0.8072645 ]
Iteration 27 [14.0 s]: loss = 0.9373 [21.3 s], NDCG = 
[ 0.76798472  0.75277577  0.74835787  0.74804731  0.75270174  0.76050289
  0.7701553   0.78150315  0.79401231  0.80802396]
Iteration 28 [13.4 s]: loss = 0.9342 [20.5 s], NDCG = 
[ 0.77025961  0.75434536  0.74949346  0.74936085  0.75375347  0.76163898
  0.77108883  0.78237668  0.7947043   0.80872687]
Iteration 29 [13.4 s]: loss = 0.9315 [20.6 s], NDCG = 
[ 0.77081081  0.75499808  0.75033894  0.74984968  0.75462169  0.76220391
  0.77168617  0.78290236  0.79522849  0.80912557]
Iteration 30 [14.0 s]: loss = 0.9293 [21.0 s], NDCG = 
[ 0.77207418  0.75588877  0.75111461  0.75089806  0.75558426  0.76275698
  0.77226139  0.78346718  0.7958261   0.80962214]
Iteration 31 [13.3 s]: loss = 0.9274 [20.2 s], NDCG = 
[ 0.77378908  0.75688193  0.75198509  0.75152663  0.75627138  0.7632116
  0.77281442  0.7840005   0.79635995  0.81010957]
Iteration 32 [13.4 s]: loss = 0.9258 [20.6 s], NDCG = 
[ 0.77380795  0.75772795  0.75274845  0.75215697  0.75673512  0.76369688
  0.77328689  0.78436132  0.79669647  0.81037147]
Iteration 33 [13.4 s]: loss = 0.9243 [20.2 s], NDCG = 
[ 0.77292251  0.75824883  0.7529549   0.75264318  0.75680344  0.76392992
  0.77337944  0.78466094  0.79691094  0.81056926]
Iteration 34 [13.4 s]: loss = 0.9232 [20.3 s], NDCG = 
[ 0.77437298  0.75891887  0.75366714  0.75305011  0.75721126  0.76423876
  0.77366984  0.78501342  0.79733221  0.8108059 ]
Iteration 35 [13.4 s]: loss = 0.9221 [20.1 s], NDCG = 
[ 0.77532381  0.75932873  0.75417143  0.75332445  0.75763005  0.76454117
  0.77394616  0.78516635  0.7975291   0.81102579]
Iteration 36 [13.4 s]: loss = 0.9212 [20.0 s], NDCG = 
[ 0.77519898  0.75944266  0.75413243  0.75362782  0.7578452   0.76453396
  0.77406179  0.78538366  0.79757584  0.81113014]
Iteration 37 [13.5 s]: loss = 0.9205 [20.2 s], NDCG = 
[ 0.77577659  0.75984122  0.75450799  0.75415662  0.75806522  0.76476139
  0.77434463  0.78558748  0.79787752  0.81134801]
Iteration 38 [13.4 s]: loss = 0.9198 [20.2 s], NDCG = 
[ 0.77562975  0.76012209  0.75474655  0.75418706  0.75801395  0.76494304
  0.77437988  0.78571012  0.7979543   0.81136434]
Iteration 39 [13.4 s]: loss = 0.9192 [20.2 s], NDCG = 
[ 0.77609196  0.76014088  0.75459295  0.75427797  0.75788723  0.76507659
  0.77438981  0.78573787  0.79805848  0.81137608]
Iteration 40 [13.4 s]: loss = 0.9186 [20.3 s], NDCG = 
[ 0.77682898  0.76048212  0.75468303  0.75448122  0.75800838  0.76533755
  0.77455817  0.78580014  0.79806779  0.81153452]
Iteration 41 [13.4 s]: loss = 0.9182 [20.2 s], NDCG = 
[ 0.77716165  0.76092935  0.75474372  0.75442476  0.75823746  0.76546738
  0.77472777  0.78604334  0.79811294  0.81160838]
Iteration 42 [13.4 s]: loss = 0.9177 [20.3 s], NDCG = 
[ 0.77789615  0.7609639   0.75492161  0.75465642  0.7584057   0.76574757
  0.77488164  0.78609854  0.7981932   0.81179554]
Iteration 43 [13.5 s]: loss = 0.9173 [20.4 s], NDCG = 
[ 0.77722642  0.76026735  0.75465085  0.75445519  0.75838033  0.76555018
  0.77475843  0.78600284  0.79812982  0.81170457]
Iteration 44 [13.4 s]: loss = 0.9170 [20.3 s], NDCG = 
[ 0.77689407  0.76028589  0.75465436  0.75435661  0.75833026  0.76551944
  0.77488297  0.78604943  0.79818212  0.81168289]
Iteration 45 [13.4 s]: loss = 0.9167 [20.1 s], NDCG = 
[ 0.77645481  0.76077363  0.75458215  0.75430666  0.75843285  0.76543114
  0.77483507  0.78602484  0.79822476  0.81170582]
Iteration 46 [13.4 s]: loss = 0.9164 [20.1 s], NDCG = 
[ 0.77670604  0.760791    0.75467458  0.75439062  0.75846351  0.76551098
  0.77497331  0.78603356  0.79826306  0.81177732]
Iteration 47 [13.4 s]: loss = 0.9162 [20.3 s], NDCG = 
[ 0.77632401  0.76078685  0.7547588   0.75429011  0.758469    0.7656711
  0.77500089  0.78594373  0.79823437  0.81174696]
Iteration 48 [13.4 s]: loss = 0.9159 [20.2 s], NDCG = 
[ 0.77675792  0.7609926   0.75477335  0.75425299  0.75866705  0.7657134
  0.77496571  0.78599881  0.79837232  0.81184252]
Iteration 49 [13.4 s]: loss = 0.9157 [20.1 s], NDCG = 
[ 0.77623911  0.7608787   0.75463351  0.75411585  0.7585616   0.76563565
  0.77493572  0.78590372  0.79832337  0.81173991]
Iteration 50 [13.4 s]: loss = 0.9155 [20.2 s], NDCG = 
[ 0.77668246  0.76091449  0.75465183  0.75403879  0.75866281  0.76566602
  0.77492679  0.78596981  0.79839166  0.81185295]
Iteration 51 [13.8 s]: loss = 0.9153 [20.3 s], NDCG = 
[ 0.77642305  0.76088681  0.75467242  0.75408511  0.75869939  0.76567293
  0.7750024   0.78596496  0.79835384  0.81184691]
Iteration 52 [13.4 s]: loss = 0.9151 [20.2 s], NDCG = 
[ 0.77637526  0.76078846  0.75451584  0.75407892  0.75869882  0.76567085
  0.77499375  0.78602198  0.79829953  0.81179944]
Iteration 53 [13.4 s]: loss = 0.9149 [20.2 s], NDCG = 
[ 0.77596556  0.76072322  0.75445373  0.7540907   0.75865849  0.76564694
  0.77502647  0.78603536  0.79836736  0.81175708]
Iteration 54 [13.4 s]: loss = 0.9147 [20.3 s], NDCG = 
[ 0.77610516  0.76060625  0.75434619  0.75407274  0.75869219  0.76556703
  0.77498695  0.78598514  0.7983534   0.81177735]
Iteration 55 [13.4 s]: loss = 0.9145 [20.3 s], NDCG = 
[ 0.77601555  0.76036446  0.75414337  0.75400713  0.7588438   0.76551008
  0.774932    0.78585129  0.79832581  0.811752  ]
Iteration 56 [13.3 s]: loss = 0.9144 [20.3 s], NDCG = 
[ 0.77566528  0.76035298  0.75417054  0.7539435   0.75863544  0.76556101
  0.77487456  0.78585281  0.79831333  0.81173818]
Iteration 57 [13.4 s]: loss = 0.9143 [20.2 s], NDCG = 
[ 0.77523766  0.7603212   0.7541935   0.75382255  0.75851379  0.76546637
  0.77478514  0.78583753  0.79825278  0.81169595]
Iteration 58 [13.4 s]: loss = 0.9141 [21.1 s], NDCG = 
[ 0.7759948   0.76040974  0.75439071  0.75389077  0.75870218  0.76560797
  0.77485414  0.78595283  0.79834771  0.81182221]
Iteration 59 [13.5 s]: loss = 0.9140 [20.2 s], NDCG = 
[ 0.77538638  0.76034751  0.7543578   0.7538391   0.75859831  0.76552039
  0.77472384  0.78589455  0.79826044  0.81171971]
Iteration 60 [13.5 s]: loss = 0.9138 [20.7 s], NDCG = 
[ 0.77528922  0.76031764  0.75441758  0.75369993  0.75851535  0.76549357
  0.77468772  0.7858685   0.7982742   0.8117455 ]
Iteration 61 [13.5 s]: loss = 0.9137 [20.6 s], NDCG = 
[ 0.77508516  0.76029702  0.75447157  0.75364186  0.75853529  0.76551133
  0.77470846  0.78583448  0.79824154  0.8117253 ]
Iteration 62 [13.4 s]: loss = 0.9135 [20.3 s], NDCG = 
[ 0.77454402  0.75998417  0.75453057  0.75352429  0.75842486  0.7654105
  0.77464573  0.78576075  0.79818511  0.81162736]
Iteration 63 [13.4 s]: loss = 0.9134 [20.4 s], NDCG = 
[ 0.77464653  0.75988759  0.75441843  0.75361717  0.75848361  0.76537555
  0.77461205  0.78576449  0.79812897  0.81166172]
Iteration 64 [13.4 s]: loss = 0.9133 [20.1 s], NDCG = 
[ 0.77446542  0.7598621   0.75437779  0.75375053  0.7584019   0.76527759
  0.77458381  0.78571779  0.79821671  0.8115871 ]
Iteration 65 [13.4 s]: loss = 0.9131 [21.1 s], NDCG = 
[ 0.77412112  0.75962793  0.75423929  0.75361602  0.7583538   0.76531185
  0.77457184  0.78572552  0.79816923  0.81156045]


liurui@ubuntu:~/NeuMF_Regression$ KERAS_BACKEND=theano python MLP.py --learner adam --reg_layers [0.00001,0.0001,0.001,0.01] --lr 0.00001
Using Theano backend.
MLP arguments: Namespace(batch_size=256, dataset='yelp', epochs=100, layers='[64,32,16,8]', learner='adam', lr=1e-05, out=1, path='Data/', reg_layers='[0.00001,0.0001,0.001,0.01]', verbose=1) 
Load data done [4.5 s]. #user=13679, #item=12922, #train=323348, #test=316795
Init: NDCG = 
[ 0.55321965  0.56002445  0.56859688  0.5790727   0.59196604  0.60714462
  0.62426632  0.64338582  0.66411189  0.68609732]
Iteration 0 [17.6 s]: loss = 15.7151 [19.6 s], NDCG = 
[ 0.57576736  0.57973082  0.58646494  0.59594451  0.60719764  0.62136904
  0.63730396  0.65560673  0.67538662  0.69687069]
Iteration 1 [15.3 s]: loss = 15.3189 [19.6 s], NDCG = 
[ 0.60033276  0.60294654  0.60745451  0.61554982  0.62628367  0.63837659
  0.65322351  0.67034302  0.68880661  0.70975362]
Iteration 2 [15.2 s]: loss = 14.6065 [19.6 s], NDCG = 
[ 0.60777907  0.61331939  0.61813718  0.62556637  0.63649999  0.64875106
  0.6630681   0.67908363  0.69742948  0.7171348 ]
Iteration 3 [15.4 s]: loss = 13.4242 [19.6 s], NDCG = 
[ 0.61160064  0.61654749  0.62112546  0.62934581  0.63962393  0.65189094
  0.66617687  0.68212711  0.7000088   0.7198493 ]
Iteration 4 [15.3 s]: loss = 11.7028 [19.7 s], NDCG = 
[ 0.61258103  0.61731659  0.62244876  0.62985087  0.64078116  0.65348857
  0.66733126  0.68322778  0.7011104   0.72081047]
Iteration 5 [15.2 s]: loss = 9.4864 [19.5 s], NDCG = 
[ 0.61346803  0.61762122  0.62318038  0.63059983  0.64195193  0.65426468
  0.66816166  0.68426412  0.7018928   0.72180086]
Iteration 6 [15.5 s]: loss = 6.9740 [19.6 s], NDCG = 
[ 0.61604415  0.61952524  0.62511503  0.63242343  0.6435995   0.65569331
  0.66968689  0.68571941  0.70318301  0.72313896]
Iteration 7 [15.4 s]: loss = 4.5494 [19.7 s], NDCG = 
[ 0.62050024  0.6229279   0.62833763  0.6356512   0.64650423  0.65837442
  0.67252995  0.6882909   0.705894    0.72552535]
Iteration 8 [15.6 s]: loss = 2.7224 [19.8 s], NDCG = 
[ 0.62846724  0.63062579  0.63458121  0.64162367  0.65217619  0.66368864
  0.67755341  0.69319776  0.7107      0.72995627]
Iteration 9 [15.2 s]: loss = 1.8149 [19.6 s], NDCG = 
[ 0.64193707  0.64272326  0.64541687  0.65141788  0.66126576  0.67254453
  0.68577239  0.70121701  0.71838057  0.73687511]
Iteration 10 [15.3 s]: loss = 1.5310 [19.8 s], NDCG = 
[ 0.65688251  0.6557785   0.65711244  0.66281328  0.67137248  0.6824143
  0.69566319  0.71017875  0.72680291  0.7448335 ]
Iteration 11 [15.3 s]: loss = 1.4236 [19.6 s], NDCG = 
[ 0.67178676  0.6687197   0.66913918  0.67392452  0.68236176  0.69227846
  0.70492822  0.71905418  0.73519116  0.752719  ]
Iteration 12 [15.3 s]: loss = 1.3476 [19.5 s], NDCG = 
[ 0.68686584  0.68130112  0.68038873  0.68436571  0.69238667  0.70202384
  0.71395325  0.72780956  0.74356747  0.76041927]
Iteration 13 [15.5 s]: loss = 1.2874 [19.6 s], NDCG = 
[ 0.7010164   0.69252892  0.69046493  0.69359275  0.70108739  0.71065241
  0.72222126  0.7358769   0.75115206  0.76750406]
Iteration 14 [15.5 s]: loss = 1.2391 [19.9 s], NDCG = 
[ 0.71089608  0.70166027  0.69907689  0.70149607  0.70851047  0.71781224
  0.72945384  0.74286733  0.75761457  0.77382889]
Iteration 15 [15.6 s]: loss = 1.1999 [20.5 s], NDCG = 
[ 0.71997082  0.709512    0.70671914  0.70940619  0.71549765  0.72465901
  0.73598115  0.74926868  0.76371695  0.77948279]
Iteration 16 [16.0 s]: loss = 1.1672 [21.1 s], NDCG = 
[ 0.72701335  0.71597566  0.71277701  0.71519446  0.72138282  0.72992856
  0.7412436   0.75466344  0.7687847   0.7839349 ]
Iteration 17 [16.3 s]: loss = 1.1395 [21.7 s], NDCG = 
[ 0.73270389  0.72168299  0.71839656  0.72007046  0.72611092  0.73491758
  0.74588311  0.7590075   0.77290977  0.78792281]
Iteration 18 [16.4 s]: loss = 1.1158 [21.8 s], NDCG = 
[ 0.73923238  0.72653434  0.72251377  0.72492267  0.73035991  0.73890078
  0.74990263  0.76262966  0.77634008  0.79120768]
Iteration 19 [16.6 s]: loss = 1.0955 [22.1 s], NDCG = 
[ 0.74428746  0.73161578  0.72715603  0.72839339  0.73432554  0.74280867
  0.75341966  0.76571365  0.77925227  0.79409222]
Iteration 20 [16.7 s]: loss = 1.0779 [22.3 s], NDCG = 
[ 0.74910545  0.73569577  0.73028059  0.73200038  0.73760734  0.74581718
  0.75625306  0.76849145  0.78188296  0.79663208]
Iteration 21 [17.1 s]: loss = 1.0628 [23.7 s], NDCG = 
[ 0.75252707  0.73855631  0.73373272  0.73437377  0.74010304  0.74793446
  0.75853684  0.77065508  0.78405643  0.79858245]
Iteration 22 [17.6 s]: loss = 1.0499 [24.2 s], NDCG = 
[ 0.75598579  0.7410351   0.73590614  0.73682726  0.74234875  0.75002034
  0.76057444  0.7726826   0.78580693  0.80028315]
Iteration 23 [18.8 s]: loss = 1.0387 [26.0 s], NDCG = 
[ 0.75868013  0.7435454   0.73821369  0.73876868  0.74412816  0.75216136
  0.76249949  0.77445519  0.78756482  0.80170653]
Iteration 24 [18.4 s]: loss = 1.0291 [25.7 s], NDCG = 
[ 0.75916781  0.74507915  0.73958043  0.74029661  0.7457716   0.75400033
  0.76396534  0.77595856  0.78868323  0.80285179]
Iteration 25 [18.6 s]: loss = 1.0209 [25.8 s], NDCG = 
[ 0.76285607  0.74681216  0.74150743  0.74232492  0.747697    0.75572298
  0.76580028  0.77747337  0.79011714  0.80416187]
Iteration 26 [18.5 s]: loss = 1.0139 [26.0 s], NDCG = 
[ 0.76496526  0.74841509  0.74329471  0.74402561  0.74905866  0.75705426
  0.76712591  0.77854683  0.79119683  0.80526674]
Iteration 27 [18.7 s]: loss = 1.0080 [25.6 s], NDCG = 
[ 0.76562336  0.75037094  0.74474006  0.74559867  0.75029373  0.7581694
  0.76819708  0.77947198  0.79197209  0.80609661]
Iteration 28 [19.0 s]: loss = 1.0029 [27.0 s], NDCG = 
[ 0.76627454  0.75162546  0.74610397  0.74681947  0.75140455  0.75909888
  0.76909915  0.78027563  0.79275097  0.80700047]
Iteration 29 [19.4 s]: loss = 0.9985 [27.1 s], NDCG = 
[ 0.76792403  0.75255207  0.74768001  0.74772374  0.75240934  0.75986783
  0.76998008  0.78121655  0.793679    0.80759565]
Iteration 30 [19.3 s]: loss = 0.9947 [27.3 s], NDCG = 
[ 0.76942009  0.75381393  0.74855837  0.74868146  0.7535202   0.76097497
  0.77078679  0.78196507  0.79442417  0.80831075]
Iteration 31 [19.4 s]: loss = 0.9914 [27.3 s], NDCG = 
[ 0.77007096  0.75513858  0.74943297  0.74965608  0.75463186  0.7616825
  0.77144929  0.78267577  0.79497797  0.80885952]
Iteration 32 [19.4 s]: loss = 0.9886 [27.3 s], NDCG = 
[ 0.77067309  0.75582802  0.75030255  0.75043539  0.75524972  0.76214961
  0.77192512  0.78313881  0.79542503  0.80926805]
Iteration 33 [19.6 s]: loss = 0.9861 [27.1 s], NDCG = 
[ 0.77169435  0.75620554  0.75112799  0.75118289  0.75572579  0.76255451
  0.7724939   0.78359962  0.79589208  0.80967988]
Iteration 34 [19.7 s]: loss = 0.9840 [26.2 s], NDCG = 
[ 0.77276215  0.75664786  0.7520936   0.75180565  0.75628584  0.76309655
  0.77299218  0.7839301   0.79614052  0.80998518]
Iteration 35 [18.8 s]: loss = 0.9821 [24.3 s], NDCG = 
[ 0.77337341  0.75719066  0.75255726  0.75220893  0.75654615  0.76340806
  0.77322924  0.78424303  0.79659432  0.81019643]
Iteration 36 [19.3 s]: loss = 0.9805 [27.1 s], NDCG = 
[ 0.77381455  0.75801704  0.75303315  0.75251842  0.75693824  0.76376592
  0.77336054  0.78456362  0.79688518  0.8104864 ]
Iteration 37 [19.6 s]: loss = 0.9790 [27.3 s], NDCG = 
[ 0.77452673  0.75864132  0.75340492  0.75295175  0.75728298  0.76421997
  0.77361144  0.78477468  0.79729693  0.81083359]
Iteration 38 [19.7 s]: loss = 0.9776 [27.3 s], NDCG = 
[ 0.77458238  0.7587236   0.75373072  0.75294446  0.75743153  0.76442281
  0.77366898  0.78494213  0.79742205  0.81088664]
Iteration 39 [19.6 s]: loss = 0.9764 [27.4 s], NDCG = 
[ 0.77454088  0.75893995  0.75366842  0.75311042  0.75746214  0.76444663
  0.7738227   0.78500816  0.79753401  0.81110637]
Iteration 40 [19.6 s]: loss = 0.9754 [27.3 s], NDCG = 
[ 0.77440662  0.75914169  0.75388643  0.7535054   0.75761145  0.76471807
  0.7739969   0.78504187  0.7976129   0.81122062]
Iteration 41 [19.8 s]: loss = 0.9744 [27.1 s], NDCG = 
[ 0.77506     0.75924434  0.7539494   0.75348753  0.75783704  0.76494228
  0.77410306  0.78519401  0.79774061  0.81130533]
Iteration 42 [19.7 s]: loss = 0.9735 [27.2 s], NDCG = 
[ 0.77449277  0.75922159  0.75381587  0.75352449  0.75777519  0.76489944
  0.77417727  0.78525094  0.79781134  0.81136879]
Iteration 43 [19.7 s]: loss = 0.9727 [27.3 s], NDCG = 
[ 0.77553385  0.75981033  0.75408479  0.75381145  0.75789741  0.76522362
  0.77445755  0.78549543  0.79798419  0.8115269 ]
Iteration 44 [19.8 s]: loss = 0.9720 [27.4 s], NDCG = 
[ 0.77529614  0.75960913  0.75391834  0.75374181  0.75799876  0.76511583
  0.77429709  0.78550307  0.79798539  0.81148827]
Iteration 45 [19.9 s]: loss = 0.9713 [27.2 s], NDCG = 
[ 0.77564704  0.75982265  0.75424249  0.75391596  0.75807871  0.76526947
  0.77450608  0.78557372  0.79810063  0.81156507]
Iteration 46 [19.8 s]: loss = 0.9706 [26.8 s], NDCG = 
[ 0.77631332  0.7600404   0.7543947   0.75408236  0.75817868  0.7653787
  0.77461226  0.78567855  0.79820031  0.81164932]
Iteration 47 [19.1 s]: loss = 0.9700 [24.3 s], NDCG = 
[ 0.77638815  0.76017318  0.75450103  0.75406381  0.75831068  0.76550539
  0.77465355  0.78573218  0.79819944  0.81168353]
Iteration 48 [19.0 s]: loss = 0.9695 [24.4 s], NDCG = 
[ 0.77619069  0.76006327  0.75435251  0.75401458  0.75831916  0.76525812
  0.77454216  0.78573334  0.7981483   0.81167186]
Iteration 49 [19.0 s]: loss = 0.9689 [24.3 s], NDCG = 
[ 0.77658561  0.76034294  0.75457905  0.75413379  0.75838369  0.76537591
  0.77473985  0.7859463   0.79828085  0.81179736]
Iteration 50 [19.1 s]: loss = 0.9684 [24.5 s], NDCG = 
[ 0.77601146  0.76029926  0.75452952  0.75395742  0.7583634   0.76536672
  0.77469676  0.78587662  0.79830629  0.81173901]
Iteration 51 [19.0 s]: loss = 0.9679 [24.4 s], NDCG = 
[ 0.77580394  0.76024642  0.75469955  0.75402415  0.75824563  0.76529036
  0.77478117  0.785835    0.79833508  0.81173976]
Iteration 52 [19.0 s]: loss = 0.9675 [25.0 s], NDCG = 
[ 0.77590299  0.76019158  0.75477027  0.7541687   0.75840077  0.76542454
  0.77487244  0.78589119  0.79829211  0.81178694]
Iteration 53 [19.0 s]: loss = 0.9670 [24.2 s], NDCG = 
[ 0.77583696  0.7599786   0.75462757  0.75420957  0.75849583  0.76539563
  0.77487759  0.78594661  0.79831186  0.81178707]
Iteration 54 [19.0 s]: loss = 0.9666 [24.4 s], NDCG = 
[ 0.77548322  0.75996749  0.75451529  0.75411043  0.75847293  0.76537749
  0.77491249  0.78591485  0.79837933  0.81169368]
Iteration 55 [19.1 s]: loss = 0.9662 [24.2 s], NDCG = 
[ 0.77540776  0.75977347  0.75446181  0.75412027  0.75852655  0.76537785
  0.77487886  0.78583402  0.79827626  0.81170922]
Iteration 56 [19.1 s]: loss = 0.9659 [24.2 s], NDCG = 
[ 0.77556089  0.75996684  0.75452571  0.75392946  0.75848411  0.76534878
  0.77502492  0.78586251  0.79834644  0.8117193 ]
Iteration 57 [19.0 s]: loss = 0.9655 [24.2 s], NDCG = 
[ 0.77495373  0.75992012  0.75452731  0.75391062  0.75848603  0.76528523
  0.7748735   0.78586195  0.79827115  0.81168211]
Iteration 58 [19.1 s]: loss = 0.9651 [27.1 s], NDCG = 
[ 0.77524552  0.76003257  0.75461368  0.75401791  0.75847443  0.76539211
  0.77493169  0.78588934  0.79823553  0.81176188]
Iteration 59 [19.8 s]: loss = 0.9648 [27.3 s], NDCG = 
[ 0.7756593   0.76009642  0.75455695  0.7540481   0.75863602  0.76542051
  0.77503236  0.78596927  0.79839243  0.81179597]
Iteration 60 [19.9 s]: loss = 0.9644 [26.2 s], NDCG = 
[ 0.77520024  0.76037779  0.75435191  0.75402754  0.75853608  0.76540598
  0.77501817  0.78589891  0.79831147  0.81175716]
Iteration 61 [18.9 s]: loss = 0.9641 [23.7 s], NDCG = 
[ 0.77554454  0.76017292  0.75452484  0.7540376   0.75859433  0.76548334
  0.77503244  0.78596502  0.79835881  0.81177108]
Iteration 62 [18.9 s]: loss = 0.9638 [24.3 s], NDCG = 
[ 0.77544958  0.76018059  0.75455087  0.75400014  0.75853865  0.7654809
  0.77501332  0.78589474  0.79834463  0.8118251 ]
Iteration 63 [19.3 s]: loss = 0.9635 [23.6 s], NDCG = 
[ 0.77547316  0.76026424  0.75455166  0.75408281  0.75858545  0.76553856
  0.77500656  0.78589753  0.79842673  0.81182675]
Iteration 64 [18.9 s]: loss = 0.9632 [23.5 s], NDCG = 
[ 0.77486348  0.76001391  0.75435473  0.75385018  0.75844828  0.76531511
  0.77483213  0.78577715  0.79834666  0.81170171]
Iteration 65 [18.9 s]: loss = 0.9629 [26.6 s], NDCG = 
[ 0.77508516  0.76006045  0.75435895  0.75391671  0.75849133  0.76548607
  0.77486693  0.78580955  0.79836233  0.81169948]
Iteration 66 [20.2 s]: loss = 0.9626 [27.8 s], NDCG = 
[ 0.77510276  0.76012826  0.75446541  0.75391498  0.75855914  0.76556222
  0.77483602  0.78577523  0.79835608  0.81167832]
Iteration 67 [20.2 s]: loss = 0.9623 [27.8 s], NDCG = 
[ 0.77526784  0.76032139  0.75444987  0.75393361  0.7586662   0.76561797
  0.77483338  0.78586522  0.7983869   0.81174419]
Iteration 68 [20.1 s]: loss = 0.9620 [27.8 s], NDCG = 
[ 0.7750534   0.7599096   0.75437024  0.75384197  0.75846618  0.76557336
  0.77468275  0.78584664  0.79836197  0.81171872]
Iteration 69 [20.1 s]: loss = 0.9617 [27.8 s], NDCG = 
[ 0.77531029  0.76013347  0.75432407  0.75383694  0.75863081  0.76559613
  0.77479783  0.78588731  0.79835148  0.81171501]
Iteration 70 [20.3 s]: loss = 0.9615 [27.4 s], NDCG = 
[ 0.77495435  0.76005124  0.75431555  0.75378165  0.75853002  0.765562
  0.77471886  0.78585148  0.79826799  0.81163667]
Iteration 71 [19.9 s]: loss = 0.9612 [27.2 s], NDCG = 
[ 0.7746242   0.75979673  0.75440552  0.75362296  0.75850514  0.76545199
  0.77475106  0.78579378  0.79830994  0.8115612 ]
Iteration 72 [19.9 s]: loss = 0.9610 [27.2 s], NDCG = 
[ 0.77418212  0.75967646  0.75435042  0.75365688  0.75846239  0.76542986
  0.77478559  0.78583149  0.79829413  0.81156373]
Iteration 73 [19.6 s]: loss = 0.9607 [24.6 s], NDCG = 
[ 0.77420098  0.75981049  0.75433393  0.75366689  0.75852094  0.76541077
  0.77474437  0.78578474  0.79828179  0.81154289]
Iteration 74 [19.1 s]: loss = 0.9604 [24.3 s], NDCG = 
[ 0.77453805  0.7600039   0.75441267  0.75363068  0.75853087  0.76544807
  0.77473091  0.78590213  0.79832535  0.81158064]
Iteration 75 [19.1 s]: loss = 0.9602 [24.3 s], NDCG = 
[ 0.77471727  0.76011696  0.75448423  0.75368482  0.75852693  0.76554112
  0.77469376  0.78589034  0.79834879  0.81157306]
Iteration 76 [19.8 s]: loss = 0.9600 [27.3 s], NDCG = 
[ 0.77477387  0.76008717  0.75458487  0.75362795  0.75853873  0.76553609
  0.77472696  0.78592115  0.79830883  0.81161028]
Iteration 77 [20.0 s]: loss = 0.9597 [27.2 s], NDCG = 
[ 0.77408527  0.75980703  0.75442743  0.75347191  0.75841372  0.76539037
  0.77456744  0.78577981  0.79820823  0.81147032]
Iteration 78 [20.1 s]: loss = 0.9595 [27.2 s], NDCG = 
[ 0.77462483  0.75970238  0.75446878  0.75345021  0.75847338  0.76539805
  0.7746474   0.78584842  0.79824196  0.81152169]
Iteration 79 [20.0 s]: loss = 0.9593 [27.2 s], NDCG = 
[ 0.77503799  0.76000641  0.7544413   0.75353416  0.75849363  0.76548547
  0.77468425  0.78589653  0.79831028  0.811661  ]
Iteration 80 [19.9 s]: loss = 0.9590 [27.2 s], NDCG = 
[ 0.77518011  0.76003339  0.75457815  0.75363289  0.75853206  0.76555869
  0.7746354   0.78598391  0.79833692  0.81168857]
Iteration 81 [19.9 s]: loss = 0.9588 [27.2 s], NDCG = 
[ 0.77529803  0.76008043  0.75446914  0.75349584  0.75840758  0.76558441
  0.77468639  0.78592854  0.79832811  0.81164239]
Iteration 82 [19.9 s]: loss = 0.9586 [27.4 s], NDCG = 
[ 0.77519426  0.76002105  0.75451539  0.75355484  0.75848302  0.76566049
  0.77468034  0.7860236   0.79832939  0.81163708]
Iteration 83 [19.9 s]: loss = 0.9583 [27.2 s], NDCG = 
[ 0.77495624  0.76012119  0.75467645  0.75354076  0.75851816  0.76569919
  0.77471045  0.78600808  0.79834272  0.81161434]
Iteration 84 [19.9 s]: loss = 0.9581 [27.2 s], NDCG = 
[ 0.77466131  0.76001278  0.75465407  0.75356475  0.75852524  0.76564049
  0.77472178  0.78596857  0.79832723  0.81164177]
Iteration 85 [19.9 s]: loss = 0.9579 [27.4 s], NDCG = 
[ 0.77463081  0.76009767  0.75458855  0.75355844  0.75844466  0.76567548
  0.77473604  0.7859093   0.79833054  0.81163364]
Iteration 86 [19.9 s]: loss = 0.9577 [27.2 s], NDCG = 
[ 0.77504114  0.76023792  0.75464005  0.75370074  0.75853016  0.76567178
  0.77474226  0.7859624   0.79833679  0.81163533]
Iteration 87 [19.9 s]: loss = 0.9575 [27.4 s], NDCG = 
[ 0.77501032  0.76017703  0.75471899  0.7536291   0.75848952  0.76567081
  0.77469596  0.78591449  0.79839912  0.81163918]
Iteration 88 [20.0 s]: loss = 0.9573 [27.1 s], NDCG = 
[ 0.77494586  0.76012101  0.75468279  0.75357589  0.75848382  0.765652
  0.77468017  0.78589662  0.79832464  0.81161818]
Iteration 89 [19.8 s]: loss = 0.9571 [27.4 s], NDCG = 
[ 0.77471476  0.76013768  0.75454601  0.7534562   0.75843418  0.76563142
  0.77462792  0.78584417  0.79827497  0.8116281 ]
Iteration 90 [19.9 s]: loss = 0.9569 [27.2 s], NDCG = 
[ 0.77444624  0.75972289  0.75444274  0.75341463  0.75832156  0.76557905
  0.77464954  0.7858641   0.7982076   0.81157363]
Iteration 91 [19.8 s]: loss = 0.9567 [27.6 s], NDCG = 
[ 0.77468992  0.75994924  0.75449958  0.753558    0.75839968  0.7656083
  0.77462314  0.78591735  0.79827071  0.81165574]
Iteration 92 [19.9 s]: loss = 0.9565 [27.1 s], NDCG = 
[ 0.77471696  0.75998447  0.75435642  0.75352758  0.75845645  0.7656407
  0.77463851  0.78586712  0.79826717  0.81168818]
Iteration 93 [19.9 s]: loss = 0.9563 [27.2 s], NDCG = 
[ 0.77442454  0.75977933  0.75443313  0.75352084  0.75832585  0.76559758
  0.77456327  0.78579714  0.79816482  0.81162701]
Iteration 94 [19.9 s]: loss = 0.9561 [27.1 s], NDCG = 
[ 0.7742123   0.75987267  0.75428987  0.75351864  0.75829675  0.76549079
  0.77454138  0.7857702   0.7981733   0.81155844]
Iteration 95 [19.8 s]: loss = 0.9559 [27.2 s], NDCG = 
[ 0.77474998  0.76003172  0.75424691  0.75361726  0.75832228  0.7655007
  0.77463201  0.78589287  0.79816127  0.81164567]
Iteration 96 [19.9 s]: loss = 0.9557 [27.1 s], NDCG = 
[ 0.7742123   0.7599253   0.75430669  0.75339322  0.75823614  0.76544101
  0.77459368  0.78580065  0.79811253  0.81155075]
Iteration 97 [19.9 s]: loss = 0.9556 [27.2 s], NDCG = 
[ 0.77448586  0.75989051  0.75428516  0.75347167  0.75841301  0.76546449
  0.77460983  0.78581921  0.79817959  0.81161932]
Iteration 98 [19.9 s]: loss = 0.9553 [27.4 s], NDCG = 
[ 0.7750141   0.76002749  0.75440123  0.75353854  0.75851284  0.76552282
  0.7746629   0.785858    0.79824632  0.81166331]
Iteration 99 [19.9 s]: loss = 0.9552 [27.4 s], NDCG = 
[ 0.77481601  0.76008777  0.75429228  0.75358709  0.75852275  0.76548865
  0.77461043  0.78584396  0.79824115  0.8116772 ]
End. Best Iteration 63:  NDCG = 0.811827. 



