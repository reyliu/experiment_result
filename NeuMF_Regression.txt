liurui@ubuntu:~/NeuMF_Regression$ KERAS_BACKEND=theano python NeuMF.py --learner adam --dataset yelp --reg_layers [0,0,0,0] --lr 0.0001
Using Theano backend.
NeuMF arguments: Namespace(batch_size=256, dataset='yelp', epochs=100, layers='[64,32,16,8]', learner='adam', lr=0.0001, mf_pretrain='', mlp_pretrain='', num_factors=8, num_neg=4, out=1, path='Data/', reg_layers='[0,0,0,0]', reg_mf=0, verbose=1) 
Load data done [4.3 s]. #user=13679, #item=12922, #train=323348, #test=316795
Init: NDCG = 0.690145
WARNING (theano.tensor.blas): We did not found a dynamic library into the library_dir of the library we use for blas. If you use ATLAS, make sure to compile it with dynamics library.
Iteration 0 [26.0 s]: NDCG = 0.760200, loss = 7.3147 [22.5 s]
Iteration 1 [17.4 s]: NDCG = 0.797641, loss = 1.1372 [22.0 s]
Iteration 2 [17.3 s]: NDCG = 0.807206, loss = 1.0068 [22.0 s]
Iteration 3 [17.0 s]: NDCG = 0.810404, loss = 0.9785 [21.7 s]
Iteration 4 [17.2 s]: NDCG = 0.811122, loss = 0.9679 [21.6 s]
Iteration 5 [17.8 s]: NDCG = 0.811452, loss = 0.9618 [22.4 s]
Iteration 6 [17.0 s]: NDCG = 0.811421, loss = 0.9565 [22.3 s]
Iteration 7 [17.1 s]: NDCG = 0.811601, loss = 0.9512 [21.7 s]
Iteration 8 [16.9 s]: NDCG = 0.811621, loss = 0.9455 [22.7 s]
Iteration 9 [17.4 s]: NDCG = 0.811552, loss = 0.9392 [18.8 s]
Iteration 10 [16.0 s]: NDCG = 0.811339, loss = 0.9318 [18.5 s]
Iteration 11 [15.9 s]: NDCG = 0.811405, loss = 0.9236 [18.2 s]
Iteration 12 [15.9 s]: NDCG = 0.811124, loss = 0.9141 [18.3 s]
Iteration 13 [15.9 s]: NDCG = 0.810920, loss = 0.9034 [18.2 s]
Iteration 14 [16.0 s]: NDCG = 0.810829, loss = 0.8912 [18.3 s]
Iteration 15 [15.9 s]: NDCG = 0.810747, loss = 0.8770 [18.3 s]
Iteration 16 [15.9 s]: NDCG = 0.810514, loss = 0.8607 [18.3 s]
Iteration 17 [15.9 s]: NDCG = 0.809694, loss = 0.8413 [18.2 s]
Iteration 18 [15.9 s]: NDCG = 0.808966, loss = 0.8186 [18.3 s]
Iteration 19 [15.9 s]: NDCG = 0.807981, loss = 0.7933 [18.2 s]
Iteration 20 [15.9 s]: NDCG = 0.806564, loss = 0.7663 [18.2 s]
Iteration 21 [16.0 s]: NDCG = 0.805180, loss = 0.7392 [18.2 s]
Iteration 22 [16.0 s]: NDCG = 0.802900, loss = 0.7122 [18.3 s]
Iteration 23 [16.1 s]: NDCG = 0.800668, loss = 0.6855 [18.3 s]
Iteration 24 [15.9 s]: NDCG = 0.798372, loss = 0.6589 [18.3 s]
Iteration 25 [16.0 s]: NDCG = 0.795590, loss = 0.6326 [18.3 s]
Iteration 26 [15.9 s]: NDCG = 0.793112, loss = 0.6060 [18.2 s]
Iteration 27 [15.9 s]: NDCG = 0.790467, loss = 0.5798 [18.3 s]
Iteration 28 [16.0 s]: NDCG = 0.787271, loss = 0.5539 [18.3 s]
Iteration 29 [15.9 s]: NDCG = 0.784465, loss = 0.5286 [18.3 s]
Iteration 30 [15.9 s]: NDCG = 0.781523, loss = 0.5042 [18.2 s]
Iteration 31 [16.0 s]: NDCG = 0.778710, loss = 0.4804 [18.2 s]
Iteration 32 [16.0 s]: NDCG = 0.776278, loss = 0.4576 [18.2 s]
Iteration 33 [15.9 s]: NDCG = 0.774724, loss = 0.4355 [18.2 s]
Iteration 34 [15.9 s]: NDCG = 0.772428, loss = 0.4149 [18.3 s]
Iteration 35 [15.9 s]: NDCG = 0.770150, loss = 0.3952 [18.3 s]
Iteration 36 [16.0 s]: NDCG = 0.767423, loss = 0.3767 [18.2 s]
Iteration 37 [16.0 s]: NDCG = 0.766026, loss = 0.3594 [18.3 s]
Iteration 38 [15.9 s]: NDCG = 0.763945, loss = 0.3430 [18.3 s]
Iteration 39 [16.0 s]: NDCG = 0.762984, loss = 0.3276 [18.2 s]
Iteration 40 [16.0 s]: NDCG = 0.761624, loss = 0.3130 [18.3 s]
Iteration 41 [16.0 s]: NDCG = 0.760383, loss = 0.2991 [18.2 s]
Iteration 42 [15.9 s]: NDCG = 0.757847, loss = 0.2862 [18.2 s]
Iteration 43 [16.0 s]: NDCG = 0.757446, loss = 0.2740 [18.4 s]
Iteration 44 [16.0 s]: NDCG = 0.755866, loss = 0.2622 [18.3 s]
Iteration 45 [16.0 s]: NDCG = 0.754632, loss = 0.2512 [18.4 s]
Iteration 46 [16.0 s]: NDCG = 0.754984, loss = 0.2409 [18.2 s]
Iteration 47 [15.9 s]: NDCG = 0.753378, loss = 0.2306 [18.3 s]
Iteration 48 [16.0 s]: NDCG = 0.752680, loss = 0.2214 [18.3 s]
Iteration 49 [16.0 s]: NDCG = 0.751653, loss = 0.2127 [18.3 s]
Iteration 50 [16.0 s]: NDCG = 0.750281, loss = 0.2043 [18.3 s]
Iteration 51 [15.9 s]: NDCG = 0.749961, loss = 0.1966 [18.2 s]
Iteration 52 [15.9 s]: NDCG = 0.749319, loss = 0.1892 [18.2 s]
Iteration 53 [16.0 s]: NDCG = 0.748091, loss = 0.1823 [18.3 s]
Iteration 54 [15.9 s]: NDCG = 0.747430, loss = 0.1757 [18.2 s]
Iteration 55 [15.9 s]: NDCG = 0.747195, loss = 0.1696 [18.2 s]
Iteration 56 [16.0 s]: NDCG = 0.746435, loss = 0.1636 [18.3 s]
Iteration 57 [16.0 s]: NDCG = 0.746203, loss = 0.1581 [18.3 s]
Iteration 58 [15.9 s]: NDCG = 0.745133, loss = 0.1528 [18.4 s]
Iteration 59 [16.0 s]: NDCG = 0.744422, loss = 0.1477 [18.2 s]
Iteration 60 [16.0 s]: NDCG = 0.745006, loss = 0.1431 [18.3 s]
Iteration 61 [15.9 s]: NDCG = 0.744546, loss = 0.1385 [18.3 s]
Iteration 62 [15.9 s]: NDCG = 0.744090, loss = 0.1342 [18.2 s]
Iteration 63 [16.0 s]: NDCG = 0.743476, loss = 0.1301 [18.5 s]
Iteration 64 [16.0 s]: NDCG = 0.742314, loss = 0.1262 [18.2 s]
Iteration 65 [16.0 s]: NDCG = 0.742165, loss = 0.1225 [18.2 s]
Iteration 66 [16.0 s]: NDCG = 0.742169, loss = 0.1189 [18.3 s]
Iteration 67 [16.0 s]: NDCG = 0.741458, loss = 0.1155 [18.3 s]
Iteration 68 [15.9 s]: NDCG = 0.741299, loss = 0.1123 [18.2 s]
Iteration 69 [16.0 s]: NDCG = 0.740338, loss = 0.1092 [18.3 s]
Iteration 70 [15.9 s]: NDCG = 0.739957, loss = 0.1063 [18.3 s]
Iteration 71 [16.0 s]: NDCG = 0.740746, loss = 0.1033 [18.2 s]
Iteration 72 [15.9 s]: NDCG = 0.740107, loss = 0.1007 [18.3 s]
Iteration 73 [16.0 s]: NDCG = 0.739326, loss = 0.0981 [18.2 s]
Iteration 74 [15.9 s]: NDCG = 0.739759, loss = 0.0953 [18.3 s]
Iteration 75 [16.0 s]: NDCG = 0.739624, loss = 0.0930 [18.3 s]
Iteration 76 [15.9 s]: NDCG = 0.738954, loss = 0.0907 [18.3 s]
Iteration 77 [16.0 s]: NDCG = 0.738229, loss = 0.0883 [18.2 s]
Iteration 78 [16.0 s]: NDCG = 0.737993, loss = 0.0861 [18.2 s]
Iteration 79 [15.9 s]: NDCG = 0.737629, loss = 0.0841 [18.3 s]
Iteration 80 [15.9 s]: NDCG = 0.738300, loss = 0.0821 [18.2 s]
Iteration 81 [16.0 s]: NDCG = 0.737596, loss = 0.0801 [18.3 s]
Iteration 82 [16.0 s]: NDCG = 0.738073, loss = 0.0781 [18.3 s]
Iteration 83 [15.9 s]: NDCG = 0.737463, loss = 0.0764 [18.3 s]
Iteration 84 [15.9 s]: NDCG = 0.737264, loss = 0.0745 [18.2 s]
Iteration 85 [16.0 s]: NDCG = 0.737904, loss = 0.0727 [18.2 s]
Iteration 86 [15.9 s]: NDCG = 0.737749, loss = 0.0712 [18.3 s]
Iteration 87 [15.9 s]: NDCG = 0.737457, loss = 0.0695 [18.3 s]
Iteration 88 [16.0 s]: NDCG = 0.737040, loss = 0.0680 [18.3 s]
Iteration 89 [16.0 s]: NDCG = 0.736919, loss = 0.0665 [18.3 s]
Iteration 90 [15.9 s]: NDCG = 0.735911, loss = 0.0651 [18.3 s]
Iteration 91 [16.0 s]: NDCG = 0.735697, loss = 0.0636 [18.2 s]
Iteration 92 [15.9 s]: NDCG = 0.736624, loss = 0.0622 [18.2 s]
Iteration 93 [15.9 s]: NDCG = 0.735777, loss = 0.0610 [18.4 s]
Iteration 94 [16.0 s]: NDCG = 0.736155, loss = 0.0596 [18.3 s]
Iteration 95 [15.9 s]: NDCG = 0.735495, loss = 0.0583 [18.3 s]
Iteration 96 [16.0 s]: NDCG = 0.735923, loss = 0.0572 [18.2 s]
Iteration 97 [15.9 s]: NDCG = 0.735738, loss = 0.0560 [18.3 s]
Iteration 98 [16.0 s]: NDCG = 0.735316, loss = 0.0548 [18.6 s]
Iteration 99 [16.0 s]: NDCG = 0.734849, loss = 0.0537 [18.2 s]
End. Best Iteration 8:  NDCG = 0.811621. 
The best NeuMF model is saved to Pretrain/yelp_NeuMF_8_[64,32,16,8]_1511528701.h5
liurui@ubuntu:~/NeuMF_Regression$ KERAS_BACKEND=theano python NeuMF.py --learner adam --dataset yelp --reg_layers [0.00001,0.0001,0.001,0.01] --lr 0.0001
Using Theano backend.
NeuMF arguments: Namespace(batch_size=256, dataset='yelp', epochs=100, layers='[64,32,16,8]', learner='adam', lr=0.0001, mf_pretrain='', mlp_pretrain='', num_factors=8, num_neg=4, out=1, path='Data/', reg_layers='[0.00001,0.0001,0.001,0.01]', reg_mf=0, verbose=1) 
Load data done [4.4 s]. #user=13679, #item=12922, #train=323348, #test=316795
Init: NDCG = 0.689081
Iteration 0 [22.1 s]: NDCG = 0.766302, loss = 6.9453 [19.0 s]
Iteration 1 [18.3 s]: NDCG = 0.801015, loss = 1.1964 [19.0 s]
Iteration 2 [18.4 s]: NDCG = 0.808193, loss = 1.0772 [19.0 s]
Iteration 3 [18.4 s]: NDCG = 0.810321, loss = 1.0455 [19.1 s]
Iteration 4 [18.5 s]: NDCG = 0.811259, loss = 1.0306 [19.2 s]
Iteration 5 [18.6 s]: NDCG = 0.811797, loss = 1.0202 [19.2 s]
Iteration 6 [18.8 s]: NDCG = 0.811681, loss = 1.0109 [19.3 s]
Iteration 7 [19.3 s]: NDCG = 0.811855, loss = 1.0023 [19.5 s]
Iteration 8 [20.3 s]: NDCG = 0.811616, loss = 0.9934 [22.1 s]
Iteration 9 [21.1 s]: NDCG = 0.811727, loss = 0.9846 [23.1 s]
Iteration 10 [21.8 s]: NDCG = 0.811519, loss = 0.9750 [23.0 s]
Iteration 11 [22.0 s]: NDCG = 0.811842, loss = 0.9649 [22.7 s]
Iteration 12 [21.9 s]: NDCG = 0.811344, loss = 0.9539 [22.7 s]
Iteration 13 [22.0 s]: NDCG = 0.811657, loss = 0.9420 [22.7 s]
Iteration 14 [21.9 s]: NDCG = 0.811182, loss = 0.9293 [22.8 s]
Iteration 15 [22.1 s]: NDCG = 0.810766, loss = 0.9157 [22.7 s]
Iteration 16 [22.0 s]: NDCG = 0.810692, loss = 0.9010 [22.7 s]
Iteration 17 [21.9 s]: NDCG = 0.810233, loss = 0.8855 [22.7 s]
Iteration 18 [22.1 s]: NDCG = 0.809694, loss = 0.8692 [22.7 s]
Iteration 19 [22.2 s]: NDCG = 0.808875, loss = 0.8522 [22.7 s]
Iteration 20 [21.9 s]: NDCG = 0.807932, loss = 0.8346 [22.7 s]
Iteration 21 [21.9 s]: NDCG = 0.806336, loss = 0.8164 [22.7 s]
Iteration 22 [22.0 s]: NDCG = 0.805040, loss = 0.7978 [22.6 s]
Iteration 23 [22.0 s]: NDCG = 0.803719, loss = 0.7790 [22.7 s]
Iteration 24 [21.9 s]: NDCG = 0.802045, loss = 0.7600 [22.7 s]
Iteration 25 [21.9 s]: NDCG = 0.800208, loss = 0.7410 [22.6 s]
Iteration 26 [22.0 s]: NDCG = 0.798649, loss = 0.7223 [22.7 s]
Iteration 27 [22.0 s]: NDCG = 0.797447, loss = 0.7035 [22.7 s]
Iteration 28 [22.0 s]: NDCG = 0.794957, loss = 0.6851 [23.0 s]
Iteration 29 [21.9 s]: NDCG = 0.792997, loss = 0.6670 [22.7 s]
Iteration 30 [22.0 s]: NDCG = 0.790966, loss = 0.6492 [22.7 s]
Iteration 31 [22.0 s]: NDCG = 0.788776, loss = 0.6318 [22.7 s]
Iteration 32 [22.2 s]: NDCG = 0.786822, loss = 0.6149 [22.8 s]
Iteration 33 [22.0 s]: NDCG = 0.785302, loss = 0.5985 [22.8 s]
Iteration 34 [22.0 s]: NDCG = 0.783747, loss = 0.5827 [22.7 s]
Iteration 35 [22.0 s]: NDCG = 0.782032, loss = 0.5676 [22.7 s]
Iteration 36 [22.0 s]: NDCG = 0.780233, loss = 0.5531 [22.7 s]
Iteration 37 [21.9 s]: NDCG = 0.778394, loss = 0.5396 [22.8 s]
Iteration 38 [22.0 s]: NDCG = 0.776620, loss = 0.5267 [22.7 s]
Iteration 39 [21.9 s]: NDCG = 0.774988, loss = 0.5147 [22.7 s]
Iteration 40 [22.0 s]: NDCG = 0.772596, loss = 0.5034 [22.8 s]
Iteration 41 [21.9 s]: NDCG = 0.771544, loss = 0.4927 [22.7 s]
Iteration 42 [22.0 s]: NDCG = 0.771417, loss = 0.4828 [22.8 s]
Iteration 43 [21.9 s]: NDCG = 0.769104, loss = 0.4735 [22.8 s]
Iteration 44 [21.9 s]: NDCG = 0.768286, loss = 0.4647 [22.8 s]
Iteration 45 [21.9 s]: NDCG = 0.767181, loss = 0.4564 [22.7 s]
Iteration 46 [22.0 s]: NDCG = 0.766456, loss = 0.4485 [22.6 s]
Iteration 47 [21.9 s]: NDCG = 0.764741, loss = 0.4410 [22.8 s]
Iteration 48 [21.9 s]: NDCG = 0.764573, loss = 0.4341 [22.7 s]
Iteration 49 [21.9 s]: NDCG = 0.762275, loss = 0.4273 [22.6 s]
Iteration 50 [22.0 s]: NDCG = 0.761818, loss = 0.4209 [22.7 s]
Iteration 51 [21.9 s]: NDCG = 0.761495, loss = 0.4148 [22.7 s]
Iteration 52 [22.0 s]: NDCG = 0.760307, loss = 0.4089 [22.8 s]
Iteration 53 [22.0 s]: NDCG = 0.759755, loss = 0.4034 [22.8 s]
Iteration 54 [22.0 s]: NDCG = 0.759204, loss = 0.3981 [22.6 s]
Iteration 55 [22.0 s]: NDCG = 0.759344, loss = 0.3928 [22.7 s]
Iteration 56 [22.0 s]: NDCG = 0.757893, loss = 0.3880 [22.6 s]
Iteration 57 [22.0 s]: NDCG = 0.757280, loss = 0.3832 [22.6 s]
Iteration 58 [22.1 s]: NDCG = 0.756432, loss = 0.3785 [22.8 s]
Iteration 59 [22.0 s]: NDCG = 0.756976, loss = 0.3742 [22.8 s]
Iteration 60 [22.1 s]: NDCG = 0.755461, loss = 0.3699 [22.7 s]
Iteration 61 [22.0 s]: NDCG = 0.755396, loss = 0.3658 [22.8 s]
Iteration 62 [22.0 s]: NDCG = 0.754843, loss = 0.3617 [22.7 s]
Iteration 63 [22.2 s]: NDCG = 0.754477, loss = 0.3579 [22.6 s]
Iteration 64 [22.1 s]: NDCG = 0.754423, loss = 0.3543 [22.7 s]
Iteration 65 [22.0 s]: NDCG = 0.754261, loss = 0.3506 [22.6 s]
Iteration 66 [22.1 s]: NDCG = 0.753548, loss = 0.3471 [22.7 s]
Iteration 67 [22.0 s]: NDCG = 0.753062, loss = 0.3437 [22.7 s]
Iteration 68 [22.1 s]: NDCG = 0.752300, loss = 0.3404 [22.8 s]
Iteration 69 [22.0 s]: NDCG = 0.752598, loss = 0.3373 [22.8 s]
Iteration 70 [22.1 s]: NDCG = 0.751488, loss = 0.3342 [22.7 s]
Iteration 71 [22.0 s]: NDCG = 0.750638, loss = 0.3312 [22.6 s]
Iteration 72 [22.1 s]: NDCG = 0.750700, loss = 0.3282 [22.7 s]
Iteration 73 [22.0 s]: NDCG = 0.749993, loss = 0.3253 [22.8 s]
Iteration 74 [22.1 s]: NDCG = 0.750402, loss = 0.3226 [22.7 s]
Iteration 75 [22.0 s]: NDCG = 0.749407, loss = 0.3198 [22.6 s]
Iteration 76 [22.0 s]: NDCG = 0.749239, loss = 0.3172 [22.8 s]
Iteration 77 [22.0 s]: NDCG = 0.748681, loss = 0.3147 [22.7 s]
Iteration 78 [22.0 s]: NDCG = 0.748658, loss = 0.3122 [22.7 s]
Iteration 79 [22.7 s]: NDCG = 0.748019, loss = 0.3097 [22.6 s]
Iteration 80 [22.0 s]: NDCG = 0.747224, loss = 0.3073 [22.6 s]
Iteration 81 [22.0 s]: NDCG = 0.747611, loss = 0.3050 [22.7 s]
Iteration 82 [22.1 s]: NDCG = 0.746725, loss = 0.3027 [22.7 s]
Iteration 83 [22.0 s]: NDCG = 0.748476, loss = 0.3005 [22.8 s]
Iteration 84 [22.0 s]: NDCG = 0.746360, loss = 0.2983 [22.8 s]
Iteration 85 [22.0 s]: NDCG = 0.746675, loss = 0.2963 [22.7 s]
Iteration 86 [22.1 s]: NDCG = 0.745941, loss = 0.2941 [22.7 s]
Iteration 87 [22.0 s]: NDCG = 0.745717, loss = 0.2921 [22.6 s]
Iteration 88 [22.0 s]: NDCG = 0.745199, loss = 0.2901 [22.7 s]
Iteration 89 [22.0 s]: NDCG = 0.745254, loss = 0.2882 [22.8 s]
Iteration 90 [22.0 s]: NDCG = 0.744185, loss = 0.2863 [22.7 s]
Iteration 91 [22.0 s]: NDCG = 0.745258, loss = 0.2844 [22.8 s]
Iteration 92 [22.3 s]: NDCG = 0.744487, loss = 0.2825 [22.5 s]
Iteration 93 [22.0 s]: NDCG = 0.744047, loss = 0.2807 [22.6 s]
Iteration 94 [22.0 s]: NDCG = 0.744712, loss = 0.2789 [22.7 s]
Iteration 95 [22.1 s]: NDCG = 0.742601, loss = 0.2772 [22.9 s]
Iteration 96 [22.0 s]: NDCG = 0.742803, loss = 0.2755 [22.7 s]
Iteration 97 [22.0 s]: NDCG = 0.743777, loss = 0.2738 [22.7 s]
Iteration 98 [22.1 s]: NDCG = 0.743476, loss = 0.2722 [22.7 s]
Iteration 99 [22.0 s]: NDCG = 0.742632, loss = 0.2705 [22.8 s]
End. Best Iteration 7:  NDCG = 0.811855. 
The best NeuMF model is saved to Pretrain/yelp_NeuMF_8_[64,32,16,8]_1511541127.h5

